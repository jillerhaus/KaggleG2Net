{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "acbe8695",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: NVIDIA GeForce RTX 3090, compute capability 8.6\n"
     ]
    }
   ],
   "source": [
    "# General\n",
    "import os\n",
    "import numpy as np\n",
    "import sys\n",
    "from glob import glob\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "#ML\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import mixed_precision, layers\n",
    "mixed_precision.set_global_policy(\"mixed_float16\")\n",
    "AUTO = tf.data.experimental.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1d7745d",
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_devices = tf.config.list_physical_devices(\"GPU\")\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7107045",
   "metadata": {},
   "outputs": [],
   "source": [
    "Params = {\n",
    "    \"batch_size\": 128\n",
    "}"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3a1d62d5",
   "metadata": {},
   "source": [
    "model = tf.keras.Sequential([\n",
    "    layers.Input()\n",
    "    \n",
    "])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8f5ed7ad",
   "metadata": {},
   "source": [
    "def make_windows(batch, y):\n",
    "    batch=np.array(batch)\n",
    "#     print(batch.shape)\n",
    "    batch = np.transpose(batch,[1,2,0])\n",
    "#     print(batch.shape)\n",
    "    batch = tf.keras.preprocessing.timeseries_dataset_from_array(batch,\n",
    "                                                              targets=None,\n",
    "                                                              sequence_length=4,\n",
    "                                                              batch_size=4096\n",
    "                                                            )\n",
    "    print(type(batch))\n",
    "    batch = tf.transpose(batch,[3,0,1,2])\n",
    "    paddings = tf.constant([\n",
    "        [0,0],\n",
    "        [0,4096-batch.shape[1]],\n",
    "        [0,0],\n",
    "        [0,0]\n",
    "    ])\n",
    "    batch = tf.pad(batch, paddings=paddings)\n",
    "#     batch = np.array(batch)\n",
    "#     print(batch.shape)\n",
    "    return batch,y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21882e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(files, window=True):\n",
    "    dataset = tf.data.TFRecordDataset(files, num_parallel_reads = AUTO)\n",
    "    \n",
    "    def _parse_function(example_proto):\n",
    "        keys_to_feature = {}\n",
    "        keys_to_feature[\"TimeSeries\"] = tf.io.FixedLenFeature([4096,3], tf.float32)\n",
    "        keys_to_feature[\"GroundTruths\"] = tf.io.FixedLenFeature([4096,3], tf.float32)\n",
    "        \n",
    "        parsed_features = tf.io.parse_single_example(example_proto, keys_to_feature)\n",
    "        return parsed_features[\"TimeSeries\"], parsed_features[\"GroundTruths\"]\n",
    "    \n",
    "    dataset = dataset.map(_parse_function, num_parallel_calls=AUTO)\n",
    "    dataset = dataset.repeat()\n",
    "    dataset = dataset.shuffle(buffer_size=10000, reshuffle_each_iteration=True)\n",
    "    dataset = dataset.batch(Params[\"batch_size\"])\n",
    "#     dataset = dataset.cache()\n",
    "    dataset = dataset.prefetch(AUTO)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e38d9a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset_files(distances):\n",
    "    train_files = []\n",
    "    val_files = []\n",
    "    for distance in distances:\n",
    "        data_files = glob(f\"../input/synthetic-tfrec/train_{distance}*.tfrec\")\n",
    "        train_files.extend(data_files[:-2])\n",
    "        val_files.extend(data_files[-2:])\n",
    "    return train_files, val_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a434860",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../input/synthetic-tfrec\\\\train_100_12500_00.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_100_12500_01.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_100_12500_02.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_100_12500_03.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_100_12500_04.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_100_12500_05.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_150_12500_00.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_150_12500_01.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_150_12500_02.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_150_12500_03.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_150_12500_04.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_150_12500_05.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_200_12500_00.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_200_12500_01.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_200_12500_02.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_200_12500_03.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_200_12500_04.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_200_12500_05.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_200_12500_06.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_200_12500_07.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_200_2_12500_00.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_200_2_12500_01.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_200_2_12500_02.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_200_2_12500_03.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_200_2_12500_04.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_200_2_12500_05.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_250_12500_00.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_250_12500_01.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_250_12500_02.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_250_12500_03.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_250_12500_04.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_250_12500_05.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_250_12500_06.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_250_12500_07.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_250_2_12500_00.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_250_2_12500_01.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_250_2_12500_02.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_250_2_12500_03.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_250_2_12500_04.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_250_2_12500_05.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_300_12500_00.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_300_12500_01.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_300_12500_02.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_300_12500_03.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_300_12500_04.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_300_12500_05.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_300_12500_06.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_300_12500_07.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_300_2_12500_00.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_300_2_12500_01.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_300_2_12500_02.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_300_2_12500_03.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_300_2_12500_04.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_300_2_12500_05.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_300_2_12500_06.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_300_2_12500_07.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_300_3_12500_00.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_300_3_12500_01.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_300_3_12500_02.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_300_3_12500_03.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_300_3_12500_04.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_300_3_12500_05.tfrec']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_files,val_files = get_dataset_files([100,150,200,250,300])\n",
    "train_ds = load_dataset(train_files)\n",
    "val_ds = load_dataset(val_files)\n",
    "train_files"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3c98132c",
   "metadata": {},
   "source": [
    "for i in tf.keras.preprocessing.timeseries_dataset_from_array(tf.transpose(tensor[0],[1,2,0]),\n",
    "                                                              targets=None,\n",
    "                                                              length=4,\n",
    "                                                              batch_size=4096\n",
    "                                                             ):\n",
    "    result = tf.transpose(i, [3,0,1,2])\n",
    "    print(result.shape)\n",
    "    \n",
    "    break\n",
    "result = tf.pad(result, paddings=tf.constant([\n",
    "    [0,0],\n",
    "    [0,4096-result.shape[1]],\n",
    "    [0,0],\n",
    "    [0,0]\n",
    "]))\n",
    "print(result.shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "raw",
   "id": "7f0330ec",
   "metadata": {},
   "source": [
    "def make_windows(batch):\n",
    "    batch = tf.transpose(batch,[1,2,0])\n",
    "    batch = tf.keras.preprocessing.sequence.TimeseriesGenerator(batch,\n",
    "                                                              targets=None,\n",
    "                                                              length=4,\n",
    "                                                              batch_size=4096\n",
    "                                                            )\n",
    "    batch = tf.transpose(batch,[3,0,1,2])\n",
    "    paddings = tf.constant([\n",
    "        [0,0],\n",
    "        [0,4096-batch.shape[1]],\n",
    "        [0,0],\n",
    "        [0,0]\n",
    "    ])\n",
    "    batch = tf.pad(batch, paddings=paddings)\n",
    "    return batch\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9cf72642",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 1, 4), dtype=float32, numpy=\n",
       "array([[[1., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 1., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 1., 0.]],\n",
       "\n",
       "       [[0., 0., 0., 1.]]], dtype=float32)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def ownInitializer(shape, dtype=None):\n",
    "    return tf.constant([\n",
    "        [[1,0,0,0]],\n",
    "        [[0,1,0,0]],\n",
    "        [[0,0,1,0]],\n",
    "        [[0,0,0,1]]\n",
    "    ],dtype=dtype)\n",
    "\n",
    "ownInitializer(2,tf.float32)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3c6a7b07",
   "metadata": {},
   "source": [
    "def ownInitializer(shape, dtype=None):\n",
    "    return tf.constant([\n",
    "        [[1,0,0,0],[1,0,0,0],[1,0,0,0]],\n",
    "        [[0,1,0,0],[0,1,0,0],[0,1,0,0]],\n",
    "        [[0,0,1,0],[0,0,1,0],[0,0,1,0]],\n",
    "        [[0,0,0,1],[0,0,0,1],[0,0,0,1]]\n",
    "    ],dtype=dtype)\n",
    "\n",
    "ownInitializer(2,tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "55a3c709",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\apist\\AppData\\Local\\Temp/ipykernel_16864/3652148574.py:16: The name tf.keras.layers.CuDNNLSTM is deprecated. Please use tf.compat.v1.keras.layers.CuDNNLSTM instead.\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 4096, 12)          156       \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 4096, 12, 1)       0         \n",
      "_________________________________________________________________\n",
      "time_distributed (TimeDistri (None, 4096, 12, 32)      128       \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 4096, 6, 32)       0         \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, 4096, 6, 16)       1552      \n",
      "_________________________________________________________________\n",
      "time_distributed_3 (TimeDist (None, 4096, 96)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 4096, 256)         231424    \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 4096, 256)         395264    \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 4096, 256)         395264    \n",
      "_________________________________________________________________\n",
      "time_distributed_4 (TimeDist (None, 4096, 3)           771       \n",
      "=================================================================\n",
      "Total params: 1,024,559\n",
      "Trainable params: 1,024,559\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.Input(shape = [4096,3]),\n",
    "#         layers.Conv1D(kernel_size=12, filters=4,\n",
    "#                        kernel_initializer=ownInitializer, input_shape=[4096,3], trainable=True, padding=\"same\"),\n",
    "    layers.Conv1D(kernel_size=4, filters=12, padding=\"same\"),\n",
    "#     layers.ZeroPadding1D(padding=[0,3]),\n",
    "    layers.Reshape([4096,12,1]),\n",
    "    layers.TimeDistributed(layers.Conv1D(kernel_size=3, filters=32, activation=\"tanh\", padding=\"same\")),\n",
    "#     layers.TimeDistributed(layers.Conv1D(kernel_size=32, filters=64, activation=\"tanh\", padding=\"same\")),\n",
    "    \n",
    "    layers.TimeDistributed(layers.MaxPool1D()),\n",
    "    layers.TimeDistributed(layers.Conv1D(kernel_size=3, filters=16, activation=\"tanh\", padding=\"same\")),\n",
    "    layers.TimeDistributed(layers.Flatten()),\n",
    "    \n",
    "#     layers.Reshape([4093,32]),\n",
    "    layers.Bidirectional(tf.compat.v1.keras.layers.CuDNNLSTM(128, return_sequences=True)),\n",
    "    layers.Bidirectional(tf.compat.v1.keras.layers.CuDNNLSTM(128, return_sequences=True)),\n",
    "    layers.Bidirectional(tf.compat.v1.keras.layers.CuDNNLSTM(128, return_sequences=True)),\n",
    "    \n",
    "#     layers.Bidirectional(layers.LSTM(100, return_sequences=True)),\n",
    "#     layers.Bidirectional(layers.LSTM(100, return_sequences=True)),\n",
    "#     layers.Bidirectional(layers.LSTM(100, return_sequences=True)),\n",
    "    \n",
    "    \n",
    "#     layers.Bidirectional(layers.LSTM(400)),\n",
    "    \n",
    "    \n",
    "    layers.TimeDistributed(layers.Dense(3, dtype=tf.float32)),\n",
    "])\n",
    "opt = tf.keras.optimizers.Adam(learning_rate = 0.001)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=opt,\n",
    "    metrics=[\"mean_squared_error\", \"cosine_similarity\"],\n",
    "    loss=\"mean_squared_error\"\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bd90ca8c",
   "metadata": {},
   "source": [
    "for x in train_ds:\n",
    "    tensor = x\n",
    "    break\n",
    "tensor[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cab5dadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_steps = len(train_files) * 12500 // Params[\"batch_size\"]\n",
    "val_steps = len(val_files) * 12500 // Params[\"batch_size\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8068783c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import *\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor=\"val_loss\", factor=0.2,\n",
    "    patience=5, min_lr = 0.000001,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    min_delta = 0.0003,\n",
    "    mode=\"min\",\n",
    "    patience=10\n",
    ")\n",
    "\n",
    "model_checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "#     f\"{MDL_PATH}/model_{Params['version']:03}.h5\",\n",
    "    \"./model.h5\",\n",
    "    monitor=\"val_loss\",\n",
    "    verbose=0,\n",
    "    save_best_only=True,\n",
    "    save_weight_only=False,\n",
    "    mode=\"auto\",\n",
    "    save_freq=\"epoch\"\n",
    ")\n",
    "\n",
    "\n",
    "callbacks=[reduce_lr, early_stop, model_checkpoint]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "613ecd42",
   "metadata": {},
   "source": [
    "model.optimizer.learning_rate = model.optimizer.learning_rate / 10"
   ]
  },
  {
   "cell_type": "raw",
   "id": "409ba9a8",
   "metadata": {},
   "source": [
    "model = tf.keras.models.load_model(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85730b5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "6054/6054 [==============================] - 2946s 485ms/step - loss: 0.0116 - mean_squared_error: 0.0116 - cosine_similarity: 0.0404 - val_loss: 0.0100 - val_mean_squared_error: 0.0100 - val_cosine_similarity: 0.0474\n",
      "Epoch 2/60\n",
      "6054/6054 [==============================] - 2994s 495ms/step - loss: 0.0090 - mean_squared_error: 0.0090 - cosine_similarity: 0.0626 - val_loss: 0.0075 - val_mean_squared_error: 0.0075 - val_cosine_similarity: 0.0871\n",
      "Epoch 3/60\n",
      "6054/6054 [==============================] - 2997s 495ms/step - loss: 0.0083 - mean_squared_error: 0.0083 - cosine_similarity: 0.0727 - val_loss: 0.0070 - val_mean_squared_error: 0.0070 - val_cosine_similarity: 0.0949\n",
      "Epoch 4/60\n",
      "6054/6054 [==============================] - 2989s 494ms/step - loss: 0.0069 - mean_squared_error: 0.0069 - cosine_similarity: 0.0969 - val_loss: 0.0065 - val_mean_squared_error: 0.0065 - val_cosine_similarity: 0.1011\n",
      "Epoch 5/60\n",
      "6054/6054 [==============================] - 2966s 490ms/step - loss: 0.0065 - mean_squared_error: 0.0065 - cosine_similarity: 0.1043 - val_loss: 0.0062 - val_mean_squared_error: 0.0062 - val_cosine_similarity: 0.1079\n",
      "Epoch 6/60\n",
      "6054/6054 [==============================] - 3000s 496ms/step - loss: 0.0062 - mean_squared_error: 0.0062 - cosine_similarity: 0.1089 - val_loss: 0.0060 - val_mean_squared_error: 0.0060 - val_cosine_similarity: 0.1144\n",
      "Epoch 7/60\n",
      "6054/6054 [==============================] - 3001s 496ms/step - loss: 0.0061 - mean_squared_error: 0.0061 - cosine_similarity: 0.1120 - val_loss: 0.0059 - val_mean_squared_error: 0.0059 - val_cosine_similarity: 0.1166\n",
      "Epoch 8/60\n",
      "6054/6054 [==============================] - 3003s 496ms/step - loss: 0.0059 - mean_squared_error: 0.0059 - cosine_similarity: 0.1142 - val_loss: 0.0058 - val_mean_squared_error: 0.0058 - val_cosine_similarity: 0.1171\n",
      "Epoch 9/60\n",
      "6054/6054 [==============================] - 3010s 497ms/step - loss: 0.0059 - mean_squared_error: 0.0059 - cosine_similarity: 0.1154 - val_loss: 0.0058 - val_mean_squared_error: 0.0058 - val_cosine_similarity: 0.1157\n",
      "Epoch 10/60\n",
      "6054/6054 [==============================] - 3057s 505ms/step - loss: 0.0058 - mean_squared_error: 0.0058 - cosine_similarity: 0.1173 - val_loss: 0.0058 - val_mean_squared_error: 0.0058 - val_cosine_similarity: 0.1144\n",
      "Epoch 11/60\n",
      "6054/6054 [==============================] - 3049s 504ms/step - loss: 0.0057 - mean_squared_error: 0.0057 - cosine_similarity: 0.1182 - val_loss: 0.0056 - val_mean_squared_error: 0.0056 - val_cosine_similarity: 0.1209\n",
      "Epoch 12/60\n",
      "6054/6054 [==============================] - 3020s 499ms/step - loss: 0.0057 - mean_squared_error: 0.0057 - cosine_similarity: 0.1187 - val_loss: 0.0056 - val_mean_squared_error: 0.0056 - val_cosine_similarity: 0.1223\n",
      "Epoch 13/60\n",
      "6054/6054 [==============================] - 3025s 500ms/step - loss: 0.0056 - mean_squared_error: 0.0056 - cosine_similarity: 0.1200 - val_loss: 0.0056 - val_mean_squared_error: 0.0056 - val_cosine_similarity: 0.1225\n",
      "Epoch 14/60\n",
      "6054/6054 [==============================] - 2993s 494ms/step - loss: 0.0056 - mean_squared_error: 0.0056 - cosine_similarity: 0.1208 - val_loss: 0.0056 - val_mean_squared_error: 0.0056 - val_cosine_similarity: 0.1224\n",
      "Epoch 15/60\n",
      "6054/6054 [==============================] - ETA: 0s - loss: 0.0055 - mean_squared_error: 0.0055 - cosine_similarity: 0.1216"
     ]
    }
   ],
   "source": [
    "model.fit(train_ds,validation_data=val_ds, validation_steps=val_steps, steps_per_epoch=train_steps,\n",
    "          epochs=60, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff7716d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "predictions = model.predict(train_ds, steps=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1224ec89",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538ff0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "for i in range(1000,1050):\n",
    "    \n",
    "    plt.plot(predictions[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633ddb2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in train_ds:\n",
    "    plt.plot(i[1][7])\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0514205",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model1.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
