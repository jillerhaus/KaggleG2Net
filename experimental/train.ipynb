{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Notebook\n",
    "\n",
    "This notebook contains the training pipeline of the detection model. It automatically saves model performance and creates an inference `csv` file on the test dataset.\n",
    "\n",
    "Currently it has a very rudimentary implementation integrating the filter with the detection model and fine-tuning it. In the future this will be separated, as the detection network is a much too heavy head for the filter. Fine-tuning is also a challenge in this configuration, since the typical starting training learning rate for the filter is 1e-3 and for the detection model it is 1e-5. I tried training them separately while freezing the other with limited success.\n",
    "\n",
    "This notebook is designed to run locally or on a Kaggle notebook instance. It can use CPU (really, really not recommended), GPU, or TPU acceleration.\n",
    "\n",
    "### Data\n",
    "\n",
    "The data in this model is of the shape [4096,3] for each sample. It contains three time series as channels of length 2 seconds sampled at 2048 Hz. Each of the channels represents the measured strain from each of the three detectors (LIGO Hanford, LIGO Livingston, Virgo). Each of these detectors has two perpendicular arms with length 4km for the LIGO detectors and 3km for the Virgo detector. The strain describes the relative change in length between the arms and is on the order of $\\mathcal{O}(10^{-20})$ before low-pass filtering and $\\mathcal{O}(10^{-21})$ after. This is also the approximate order of expected gravitational wave measurements. The data is in most cases dominated by noise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose GPU\n",
    "\n",
    "Detects whether the notebook is running on my workstation or on kaggle. Unfortunately the environment names on kaggle are randomly generated, as far as I can tell, so you will need to enter your own computer name, or just set `KAGGLE` to `False` if you intend on running the notebook locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-17T17:22:41.713595Z",
     "iopub.status.busy": "2021-09-17T17:22:41.713335Z",
     "iopub.status.idle": "2021-09-17T17:22:41.725791Z",
     "shell.execute_reply": "2021-09-17T17:22:41.725140Z",
     "shell.execute_reply.started": "2021-09-17T17:22:41.713521Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KAGGLE: False\n"
     ]
    }
   ],
   "source": [
    "import socket\n",
    "import os\n",
    "\n",
    "KAGGLE = True\n",
    "if socket.gethostname() == \"Computerfon\":\n",
    "    KAGGLE = False\n",
    "print(f\"KAGGLE: {KAGGLE}\")\n",
    "if not KAGGLE:\n",
    "            # set available accelerator to keep tensorflow from intantiating on possible other GPUs\n",
    "            os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-17T17:22:41.727703Z",
     "iopub.status.busy": "2021-09-17T17:22:41.726861Z",
     "iopub.status.idle": "2021-09-17T17:22:43.782183Z",
     "shell.execute_reply": "2021-09-17T17:22:43.781042Z",
     "shell.execute_reply.started": "2021-09-17T17:22:41.727659Z"
    }
   },
   "outputs": [],
   "source": [
    "# general\n",
    "import os\n",
    "import gc\n",
    "import warnings\n",
    "import sklearn.exceptions\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=sklearn.exceptions.UndefinedMetricWarning)\n",
    "\n",
    "from glob import glob\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from IPython.core.display import display, HTML\n",
    "if KAGGLE:\n",
    "    from kaggle_datasets import KaggleDatasets\n",
    "\n",
    "# ML\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# DL\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "# tf.config.optimizer.set_jit(True)\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Enable memory growth to get an idea of the size of the model\n",
    "if not KAGGLE:\n",
    "    physical_devices = tf.config.list_physical_devices(\"GPU\")\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Static settings\n",
    "\n",
    "#### !Eager Execution!\n",
    "\n",
    "eager execution needs to be disabled if the model is meant for fine-tuning. This is due to a bug with the `keras` callback `modelCheckpoint`, which for some reason opens the `h5` file containing model information in `\"w\"` mode instead of `\"r+\"` which causes it to crash when training the second model, thus attempting to overwrite the file. This bug is not present when eager execution is disabled, although this will use significantly more memory, so is not advisable on the kaggle notebook. This bug can also be avoided by not using the callback on the second `keras.model.Model.fit()` call. Hopefully I will find a better solution in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-17T17:22:43.784172Z",
     "iopub.status.busy": "2021-09-17T17:22:43.783660Z",
     "iopub.status.idle": "2021-09-17T17:22:43.799591Z",
     "shell.execute_reply": "2021-09-17T17:22:43.798788Z",
     "shell.execute_reply.started": "2021-09-17T17:22:43.784124Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tf.compat.v1.disable_eager_execution()\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))\n",
    "%matplotlib inline\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TPU Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-17T17:22:43.803149Z",
     "iopub.status.busy": "2021-09-17T17:22:43.802737Z",
     "iopub.status.idle": "2021-09-17T17:22:43.811423Z",
     "shell.execute_reply": "2021-09-17T17:22:43.810381Z",
     "shell.execute_reply.started": "2021-09-17T17:22:43.803115Z"
    }
   },
   "outputs": [],
   "source": [
    "def auto_select_accelerator():\n",
    "    TPU_DETECTED = False\n",
    "    try:\n",
    "        tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "        tf.config.experimental_connect_to_cluster(tpu)\n",
    "        tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "        strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "        tf.keras.mixed_precision.set_global_policy(\"mixed_bfloat16\")\n",
    "        print(f\"Running on TPU: {tpu.master()}\")\n",
    "        TPU_DETECTED = True\n",
    "    except ValueError:\n",
    "        strategy = tf.distribute.get_strategy()\n",
    "        tf.keras.mixed_precision.set_global_policy(\"mixed_float16\")\n",
    "        \n",
    "    num_replicas = strategy.num_replicas_in_sync\n",
    "    print(f\"Running on {num_replicas} replica{'s' if num_replicas > 1 else ''}\")\n",
    "    return strategy, TPU_DETECTED, num_replicas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PARAMS\n",
    "\n",
    "More static parameters, choose the folders in `../input/` you wish to train on. The notebook works with multiple datasets at the same time and will use the last ordered file in a folder as the validation file. This is important to keep in mind, when you create datasets you want to use for simultaneous training, the same samples need to be in the same files, or else you will have a data leak."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-17T17:22:43.813082Z",
     "iopub.status.busy": "2021-09-17T17:22:43.812779Z",
     "iopub.status.idle": "2021-09-17T17:22:49.385095Z",
     "shell.execute_reply": "2021-09-17T17:22:49.384154Z",
     "shell.execute_reply.started": "2021-09-17T17:22:43.813043Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: NVIDIA GeForce RTX 3090, compute capability 8.6\n",
      "Running on 1 replica\n"
     ]
    }
   ],
   "source": [
    "strategy, TPU_Detected, REPLICAS = auto_select_accelerator()\n",
    "INPUT_DIR = \"../input/g2net-gravitational-wave-detection\"\n",
    "MDLS_PATH = \".\" if KAGGLE else \"../models\"\n",
    "# TRAIN_FILES_PATH = \"../input/filtered*_tfrec\"\n",
    "AUTO = tf.data.experimental.AUTOTUNE\n",
    "tfrec_folders = [\"like-synthetic-short-whitened-highpassed-tfrec\"]#, \"like-synthetic-whitened-highpassed-\"]#[\"whitened-longer-tfrec\", \"whitened-tfrec\", \"filtered-whitened-tfrec\"]\n",
    "if KAGGLE:\n",
    "    tfrec_folders = [\"filteredwhitenedtfrec\",\"whitened-tfrec\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show results from previous models if available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-17T17:10:49.388016Z",
     "iopub.status.busy": "2021-09-17T17:10:49.387794Z",
     "iopub.status.idle": "2021-09-17T17:10:49.406903Z",
     "shell.execute_reply": "2021-09-17T17:10:49.405619Z",
     "shell.execute_reply.started": "2021-09-17T17:10:49.387988Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lr</th>\n",
       "      <th>version</th>\n",
       "      <th>train_mode</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>epochs</th>\n",
       "      <th>bavg_epoch</th>\n",
       "      <th>bavg_loss</th>\n",
       "      <th>bavg_auc</th>\n",
       "      <th>changelog</th>\n",
       "      <th>seed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.00001</td>\n",
       "      <td>200</td>\n",
       "      <td>full</td>\n",
       "      <td>256</td>\n",
       "      <td>100</td>\n",
       "      <td>36</td>\n",
       "      <td>0.464103</td>\n",
       "      <td>0.839057</td>\n",
       "      <td>1/4 lr</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.00100</td>\n",
       "      <td>210</td>\n",
       "      <td>full</td>\n",
       "      <td>256</td>\n",
       "      <td>100</td>\n",
       "      <td>24</td>\n",
       "      <td>0.444001</td>\n",
       "      <td>0.847384</td>\n",
       "      <td>1/4 lr</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.00010</td>\n",
       "      <td>221</td>\n",
       "      <td>full</td>\n",
       "      <td>256</td>\n",
       "      <td>100</td>\n",
       "      <td>40</td>\n",
       "      <td>0.435199</td>\n",
       "      <td>0.850387</td>\n",
       "      <td>1/4 lr</td>\n",
       "      <td>69.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.00010</td>\n",
       "      <td>222</td>\n",
       "      <td>full</td>\n",
       "      <td>256</td>\n",
       "      <td>100</td>\n",
       "      <td>26</td>\n",
       "      <td>0.437144</td>\n",
       "      <td>0.849532</td>\n",
       "      <td>1/4 lr</td>\n",
       "      <td>69.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.00010</td>\n",
       "      <td>224</td>\n",
       "      <td>full</td>\n",
       "      <td>256</td>\n",
       "      <td>100</td>\n",
       "      <td>30</td>\n",
       "      <td>0.434321</td>\n",
       "      <td>0.851999</td>\n",
       "      <td>Input layers: 1/2 kernel size. more kernels</td>\n",
       "      <td>69.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.00010</td>\n",
       "      <td>231</td>\n",
       "      <td>full</td>\n",
       "      <td>256</td>\n",
       "      <td>100</td>\n",
       "      <td>29</td>\n",
       "      <td>0.439757</td>\n",
       "      <td>0.848020</td>\n",
       "      <td>only whitened ds</td>\n",
       "      <td>69.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.00010</td>\n",
       "      <td>242</td>\n",
       "      <td>full</td>\n",
       "      <td>256</td>\n",
       "      <td>25</td>\n",
       "      <td>23</td>\n",
       "      <td>0.447073</td>\n",
       "      <td>0.848576</td>\n",
       "      <td>only whitened ds with sgd</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.00010</td>\n",
       "      <td>244</td>\n",
       "      <td>full</td>\n",
       "      <td>256</td>\n",
       "      <td>25</td>\n",
       "      <td>21</td>\n",
       "      <td>0.465401</td>\n",
       "      <td>0.834070</td>\n",
       "      <td>only whitened ds with sgd</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.00010</td>\n",
       "      <td>245</td>\n",
       "      <td>full</td>\n",
       "      <td>256</td>\n",
       "      <td>25</td>\n",
       "      <td>23</td>\n",
       "      <td>0.446809</td>\n",
       "      <td>0.842836</td>\n",
       "      <td>all ds</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.00010</td>\n",
       "      <td>247</td>\n",
       "      <td>full</td>\n",
       "      <td>256</td>\n",
       "      <td>35</td>\n",
       "      <td>9</td>\n",
       "      <td>0.444699</td>\n",
       "      <td>0.842759</td>\n",
       "      <td>second run with adam</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0.00010</td>\n",
       "      <td>307</td>\n",
       "      <td>full</td>\n",
       "      <td>256</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>0.490005</td>\n",
       "      <td>0.852317</td>\n",
       "      <td>second run with adam</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0.00010</td>\n",
       "      <td>346</td>\n",
       "      <td>full</td>\n",
       "      <td>64</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0.403609</td>\n",
       "      <td>0.839891</td>\n",
       "      <td>second run with adam</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0.00001</td>\n",
       "      <td>355</td>\n",
       "      <td>full</td>\n",
       "      <td>64</td>\n",
       "      <td>35</td>\n",
       "      <td>6</td>\n",
       "      <td>0.431249</td>\n",
       "      <td>0.840779</td>\n",
       "      <td>second run with adam</td>\n",
       "      <td>69420.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0.00010</td>\n",
       "      <td>453</td>\n",
       "      <td>full</td>\n",
       "      <td>128</td>\n",
       "      <td>35</td>\n",
       "      <td>12</td>\n",
       "      <td>0.409684</td>\n",
       "      <td>0.854513</td>\n",
       "      <td>second run with adam</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0.00010</td>\n",
       "      <td>457</td>\n",
       "      <td>full</td>\n",
       "      <td>256</td>\n",
       "      <td>35</td>\n",
       "      <td>15</td>\n",
       "      <td>0.402773</td>\n",
       "      <td>0.854391</td>\n",
       "      <td>new dataset with 0.125/0.12 whitening, before ...</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0.00010</td>\n",
       "      <td>466</td>\n",
       "      <td>full</td>\n",
       "      <td>256</td>\n",
       "      <td>20</td>\n",
       "      <td>13</td>\n",
       "      <td>0.400203</td>\n",
       "      <td>0.859984</td>\n",
       "      <td>no whitening only lowpass &amp; normalization</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.00005</td>\n",
       "      <td>474</td>\n",
       "      <td>full</td>\n",
       "      <td>256</td>\n",
       "      <td>80</td>\n",
       "      <td>10</td>\n",
       "      <td>0.412824</td>\n",
       "      <td>0.855606</td>\n",
       "      <td>no whitening only lowpass &amp; normalization</td>\n",
       "      <td>1111.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.00010</td>\n",
       "      <td>475</td>\n",
       "      <td>full</td>\n",
       "      <td>256</td>\n",
       "      <td>80</td>\n",
       "      <td>11</td>\n",
       "      <td>0.409763</td>\n",
       "      <td>0.853231</td>\n",
       "      <td>using 1e-4 initial lr</td>\n",
       "      <td>1111.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0.00001</td>\n",
       "      <td>476</td>\n",
       "      <td>full</td>\n",
       "      <td>256</td>\n",
       "      <td>80</td>\n",
       "      <td>15</td>\n",
       "      <td>0.439726</td>\n",
       "      <td>0.847705</td>\n",
       "      <td>using 1e-5 initial lr</td>\n",
       "      <td>1111.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0.00010</td>\n",
       "      <td>480</td>\n",
       "      <td>full</td>\n",
       "      <td>256</td>\n",
       "      <td>35</td>\n",
       "      <td>7</td>\n",
       "      <td>0.457760</td>\n",
       "      <td>0.836264</td>\n",
       "      <td>simple detection network with same pre-process...</td>\n",
       "      <td>1111.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         lr  version train_mode  batch_size  epochs  bavg_epoch  bavg_loss  \\\n",
       "43  0.00001      200       full         256     100          36   0.464103   \n",
       "44  0.00100      210       full         256     100          24   0.444001   \n",
       "45  0.00010      221       full         256     100          40   0.435199   \n",
       "46  0.00010      222       full         256     100          26   0.437144   \n",
       "47  0.00010      224       full         256     100          30   0.434321   \n",
       "48  0.00010      231       full         256     100          29   0.439757   \n",
       "49  0.00010      242       full         256      25          23   0.447073   \n",
       "50  0.00010      244       full         256      25          21   0.465401   \n",
       "51  0.00010      245       full         256      25          23   0.446809   \n",
       "52  0.00010      247       full         256      35           9   0.444699   \n",
       "53  0.00010      307       full         256      35           1   0.490005   \n",
       "54  0.00010      346       full          64      35           0   0.403609   \n",
       "55  0.00001      355       full          64      35           6   0.431249   \n",
       "56  0.00010      453       full         128      35          12   0.409684   \n",
       "57  0.00010      457       full         256      35          15   0.402773   \n",
       "58  0.00010      466       full         256      20          13   0.400203   \n",
       "59  0.00005      474       full         256      80          10   0.412824   \n",
       "60  0.00010      475       full         256      80          11   0.409763   \n",
       "61  0.00001      476       full         256      80          15   0.439726   \n",
       "62  0.00010      480       full         256      35           7   0.457760   \n",
       "\n",
       "    bavg_auc                                          changelog     seed  \n",
       "43  0.839057                                             1/4 lr     42.0  \n",
       "44  0.847384                                             1/4 lr     42.0  \n",
       "45  0.850387                                             1/4 lr     69.0  \n",
       "46  0.849532                                             1/4 lr     69.0  \n",
       "47  0.851999        Input layers: 1/2 kernel size. more kernels     69.0  \n",
       "48  0.848020                                   only whitened ds     69.0  \n",
       "49  0.848576                          only whitened ds with sgd     42.0  \n",
       "50  0.834070                          only whitened ds with sgd     42.0  \n",
       "51  0.842836                                             all ds     42.0  \n",
       "52  0.842759                               second run with adam     42.0  \n",
       "53  0.852317                               second run with adam     42.0  \n",
       "54  0.839891                               second run with adam     42.0  \n",
       "55  0.840779                               second run with adam  69420.0  \n",
       "56  0.854513                               second run with adam     42.0  \n",
       "57  0.854391  new dataset with 0.125/0.12 whitening, before ...     42.0  \n",
       "58  0.859984          no whitening only lowpass & normalization     42.0  \n",
       "59  0.855606          no whitening only lowpass & normalization   1111.0  \n",
       "60  0.853231                              using 1e-4 initial lr   1111.0  \n",
       "61  0.847705                              using 1e-5 initial lr   1111.0  \n",
       "62  0.836264  simple detection network with same pre-process...   1111.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show results from previous models\n",
    "results_df = \"no file\"\n",
    "if not KAGGLE:\n",
    "    results_df = pd.read_csv(\"../models/results.csv\", index_col=[0]).tail(20)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Necessary when running on a Kaggle notebook using a TPU with a private dataset. In addition you need to attach your Google Cloud Services credentials to the notebook. This can be done by clicking on Add-ons -> Google Cloud SDK -> Attach to notebook in your Kaggle notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-17T17:22:49.386775Z",
     "iopub.status.busy": "2021-09-17T17:22:49.386544Z",
     "iopub.status.idle": "2021-09-17T17:22:49.599221Z",
     "shell.execute_reply": "2021-09-17T17:22:49.598282Z",
     "shell.execute_reply.started": "2021-09-17T17:22:49.386749Z"
    }
   },
   "outputs": [],
   "source": [
    "if KAGGLE:\n",
    "    from kaggle_secrets import UserSecretsClient\n",
    "    user_secrets = UserSecretsClient()\n",
    "    user_credential = user_secrets.get_gcloud_credential()\n",
    "    user_secrets.set_tensorflow_credential(user_credential)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The `Params` class\n",
    "\n",
    "This class contains the important parameters of the model. You can add ones you think are important. They will be automatically be archived in both the model performance `csv` file found at `../models/results.csv` and in a separate `JSON` file in the model directory itself. Folds have not been implemented yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-17T17:22:49.601675Z",
     "iopub.status.busy": "2021-09-17T17:22:49.601417Z",
     "iopub.status.idle": "2021-09-17T17:22:49.608611Z",
     "shell.execute_reply": "2021-09-17T17:22:49.607652Z",
     "shell.execute_reply.started": "2021-09-17T17:22:49.601646Z"
    }
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(f\"{MDLS_PATH}/results.csv\"):\n",
    "    VER = 1\n",
    "else:\n",
    "    results = pd.read_csv(f\"{MDLS_PATH}/results.csv\", index_col=[0])\n",
    "    VER = int(results.version.max())\n",
    "Params ={\n",
    "    \"lr\": 1e-4 * REPLICAS,\n",
    "    \"version\": VER,\n",
    "    \"train_mode\": \"full\", #test, full\n",
    "    \"batch_size\": 256 * REPLICAS,\n",
    "    \"epochs\": 35,\n",
    "    \"seed\": 1111,\n",
    "    \"changelog\": \"simple detection network with same pre-processing applied to synthetic training dataset as kaggle dataset\",\n",
    "}\n",
    "seed_everything(Params[\"seed\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make Model directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-17T17:22:49.609927Z",
     "iopub.status.busy": "2021-09-17T17:22:49.609716Z",
     "iopub.status.idle": "2021-09-17T17:22:49.626003Z",
     "shell.execute_reply": "2021-09-17T17:22:49.624837Z",
     "shell.execute_reply.started": "2021-09-17T17:22:49.609902Z"
    }
   },
   "outputs": [],
   "source": [
    "VER = Params[\"version\"]\n",
    "MDL_PATH = f\"{MDLS_PATH}/models_v{VER:03}\"\n",
    "while os.path.exists(MDL_PATH):\n",
    "    VER += 1\n",
    "    MDL_PATH = f\"{MDLS_PATH}/models_v{VER:03}\"\n",
    "Params[\"version\"]=VER\n",
    "os.mkdir(MDL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convenience Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Augmentation: random_cut():\n",
    "\n",
    "This augmentation function works on whole batches of data, to reduce the computational expense. It should not impact performance in this way.\n",
    "\n",
    "It is written in a way to work in all runtimes in which the notebook has been testest (kaggle, local) and (GPU, TPU).\n",
    "\n",
    "The function randomly cuts off a random amount of data points from the beginning and the end of each sample and replaces them with zeros. This is done in 35% of cases. The reason for this is, that this produces models that are resistant to overfitting, but still work on un-augmented test data during inference. More than 35% produced models that no longer generalized well, giving the impression of training two separate models. The `maxVal` variable represents the maximum value of data points cut off from both the beginning and end of the tensor. This was successful up to 512 data points or 0.25 seconds. It is not advisable to cut off more, since the signal seems to be located at around 1.5s in most cases.\n",
    "\n",
    "Independently moving the result in the output tensor, with the intent of making the models more translation invariant,  created models that no longer performed well when infering on un-augmented test data. However overfitting was reduced drastically even with more complex models. So using this together with test-time augmentation would be a good idea in the future.\n",
    "\n",
    "The function then randomly changes the sign of each of the channels independently. It might also be a good idea to randomly multiply the model with a scaling factor of 0.9-1.0 until the model is used to estimate the parameters of the gravitational waves in the future (masses of the bodies, spin, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_cut(x,y):\n",
    "    tensor = x\n",
    "    if random.random() > 0.6:\n",
    "        maxVal=256\n",
    "        dt = tf.random.uniform(shape=[],minval=2, maxval=maxVal, dtype=tf.int32)\n",
    "        t0 = tf.random.uniform(shape=[],minval=1, maxval=dt, dtype=tf.int32)\n",
    "        t1 = tf.random.uniform(shape=[],minval=0, maxval=t0, dtype=tf.int32)\n",
    "        paddings =  [\n",
    "            [0,0],\n",
    "            [t0,dt-t0], \n",
    "#             [t1, dt-t1],# if you want to move the resulting tensor randomly in the output tensor\n",
    "            [0,0]\n",
    "        ]\n",
    "        tensor = tf.pad(tensor[:,t0:t0+(4096-dt)], paddings=paddings)\n",
    "    tensor = tensor * [-1. if random.random() > 0.5 else 1.,\n",
    "                       -1. if random.random() > 0.5 else 1.,\n",
    "                       -1. if random.random() > 0.5 else 1.]\n",
    "    # Necessary for TPU runtime\n",
    "    tensor = tf.reshape(tensor,[Params[\"batch_size\"], 4096, 3])\n",
    "    # Necessary for GPU runtime\n",
    "    tensor = tf.cast(tensor, tf.float32)\n",
    "    return tensor, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load_dataset()\n",
    "Loads the dataset from folders containing `tfrec` files. The train file names are expected to begin with \"train\" and the test files with \"test\".\n",
    "\n",
    "A large shuffle buffer is recommended in a large, heterogenous dataset, i.e. if the data pre-processing is different in the datasets used. The Kaggle dataset is quite large with 560,000 train samples and 226,000 test samples. In that case pick a large shuffle buffer, that works with the available memory.\n",
    "\n",
    "It is not recommended to add caching functionality when using the Kaggle dataset, as it will use inordinate amounts of RAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-17T17:22:49.628201Z",
     "iopub.status.busy": "2021-09-17T17:22:49.627767Z",
     "iopub.status.idle": "2021-09-17T17:22:49.642197Z",
     "shell.execute_reply": "2021-09-17T17:22:49.641358Z",
     "shell.execute_reply.started": "2021-09-17T17:22:49.628155Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_dataset(files, shuffle=True, ordered=False, labeled = True, repeat=True, return_labels = False, cut = False, cache=False):\n",
    "    if ordered:\n",
    "        dataset = tf.data.TFRecordDataset(files, num_parallel_reads=None)\n",
    "    else:\n",
    "        dataset = tf.data.TFRecordDataset(files, num_parallel_reads=AUTO)\n",
    "    \n",
    "\n",
    "    def _parse_function(example_proto):\n",
    "        if labeled:\n",
    "            keys_to_feature = {\n",
    "                \"TimeSeries\":tf.io.FixedLenFeature([4096,3],tf.float32),\n",
    "                \"Target\":tf.io.FixedLenFeature([], tf.int64, default_value=0)}\n",
    "            if return_labels:\n",
    "                keys_to_feature[\"id\"]=tf.io.FixedLenFeature([],tf.string, default_value=\"\")\n",
    "        else:\n",
    "            keys_to_feature = {\n",
    "                \"TimeSeries\": tf.io.FixedLenFeature([4096,3],tf.float32)\n",
    "            }\n",
    "        parsed_features = tf.io.parse_single_example(example_proto, keys_to_feature)\n",
    "        if labeled:\n",
    "            if return_labels:\n",
    "                return parsed_features[\"TimeSeries\"], parsed_features[\"Target\"], parsed_features[\"id\"]\n",
    "            else:\n",
    "                return parsed_features[\"TimeSeries\"], parsed_features[\"Target\"]\n",
    "        else:\n",
    "            return parsed_features[\"TimeSeries\"]\n",
    "    if not ordered:\n",
    "        ignore_order = tf.data.Options()\n",
    "        ignore_order.experimental_deterministic=False\n",
    "        dataset = dataset.with_options(ignore_order)\n",
    "    # parse the record into tensors.\n",
    "    dataset = dataset.map(_parse_function, num_parallel_calls=AUTO)\n",
    "#     dataset = dataset.cache()\n",
    "\n",
    "    # Repeat the input infinitely\n",
    "    if repeat:\n",
    "        dataset = dataset.repeat()\n",
    "\n",
    "    # shuffle the dataset\n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(buffer_size=50000, reshuffle_each_iteration=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#     # Generate batches\n",
    "    dataset = dataset.batch(Params[\"batch_size\"])\n",
    "    if cut:\n",
    "        dataset = dataset.map(random_cut, num_parallel_calls=AUTO, deterministic=False)\n",
    "    dataset = dataset.prefetch(AUTO)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get_train_val_files()\n",
    "\n",
    "This function splits the available `tfrec` datasets, which can be created using `makeDataset.py` into train and val files, while also creating a list of train files, that are in the right order, for deciding which version of the test files to infer on when submitting to the competition. This functionality has been changed to only include the val files later on, since models overfit to differing degrees on datasets with different pre-processing. It also returns a list of the test files, that are used for inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-17T17:22:49.644543Z",
     "iopub.status.busy": "2021-09-17T17:22:49.644208Z",
     "iopub.status.idle": "2021-09-17T17:22:53.400603Z",
     "shell.execute_reply": "2021-09-17T17:22:53.399615Z",
     "shell.execute_reply.started": "2021-09-17T17:22:49.644502Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_train_val_files(folders):\n",
    "    train_files = []\n",
    "    val_files = []\n",
    "    test_files = []\n",
    "    all_train_files = []\n",
    "    for folder in folders:\n",
    "        if KAGGLE:\n",
    "            TRAIN_FILES_PATH = KaggleDatasets().get_gcs_path(folder)\n",
    "            TEST_FILES_PATH = KaggleDatasets().get_gcs_path(f\"{folder}test\")\n",
    "            all_files_train = np.sort(tf.io.gfile.glob(f\"{TRAIN_FILES_PATH}/train_*.tfrec\"))\n",
    "            all_files_test = np.sort(tf.io.gfile.glob(f\"{TEST_FILES_PATH}/test_*.tfrec\"))\n",
    "        else:\n",
    "            all_files_train = np.sort(glob(f\"../input/{folder}/train*.tfrec\"))\n",
    "            all_files_test = np.sort(glob(f\"../input/{folder}/test*.tfrec\"))\n",
    "        \n",
    "        if Params[\"train_mode\"] == \"test\":\n",
    "            train_files.extend(all_files_train[:1])\n",
    "            val_files.extend(all_files_train[-1:])\n",
    "            \n",
    "        else:\n",
    "            train_files.extend(all_files_train[:-2])\n",
    "            val_files.extend(all_files_train[-2:])\n",
    "        test_files.append(all_files_test)\n",
    "        all_train_files.append(all_files_train)\n",
    "    return train_files, val_files, test_files, all_train_files\n",
    "\n",
    "train_files, val_files, test_files, all_train_files = get_train_val_files(tfrec_folders)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create the Tensorflow datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-17T17:22:53.402399Z",
     "iopub.status.busy": "2021-09-17T17:22:53.402073Z",
     "iopub.status.idle": "2021-09-17T17:22:53.738249Z",
     "shell.execute_reply": "2021-09-17T17:22:53.737171Z",
     "shell.execute_reply.started": "2021-09-17T17:22:53.402358Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds = load_dataset(train_files, cut=True)\n",
    "val_ds = load_dataset(val_files, shuffle=False, cache=False, ordered=True, repeat=True)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-15T15:02:39.670012Z",
     "iopub.status.busy": "2021-09-15T15:02:39.669804Z",
     "iopub.status.idle": "2021-09-15T15:02:40.728147Z",
     "shell.execute_reply": "2021-09-15T15:02:40.727152Z",
     "shell.execute_reply.started": "2021-09-15T15:02:39.669988Z"
    }
   },
   "source": [
    "from tensorflow.keras import Sequential, layers\n",
    "with strategy.scope():\n",
    "    model = Sequential([\n",
    "        layers.Conv1D(filters=32, kernel_size=16, padding=\"causal\",input_shape=[4096,3]),\n",
    "        layers.MaxPool1D(pool_size=4),\n",
    "        layers.Activation(\"relu\"),\n",
    "        \n",
    "        layers.Conv1D(filters=64, kernel_size=8, padding=\"causal\"),\n",
    "        layers.Conv1D(filters=128, kernel_size=8, padding=\"causal\"),\n",
    "        layers.Conv1D(filters=128, kernel_size=8, padding=\"causal\"),\n",
    "        layers.MaxPool1D(pool_size=4),\n",
    "        layers.Dropout(0.4),\n",
    "        layers.Activation(\"relu\"),\n",
    "        \n",
    "        layers.Conv1D(filters=128, kernel_size=8, padding=\"causal\"),\n",
    "        layers.MaxPool1D(pool_size=4),\n",
    "        layers.Activation(\"relu\"),\n",
    "        \n",
    "        layers.Conv1D(filters=256, kernel_size=8, padding=\"causal\"),\n",
    "        layers.MaxPool1D(pool_size=4),\n",
    "        layers.Activation(\"relu\"),\n",
    "        \n",
    "        layers.Flatten(),\n",
    "        layers.Dense(128, activation=\"relu\"),\n",
    "        layers.Dense(64, activation=\"relu\"),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(1),\n",
    "        layers.Activation(\"sigmoid\", dtype=\"float32\")\n",
    "    ])\n",
    "    model.compile(\n",
    "        tf.keras.optimizers.Adam(learning_rate = Params[\"lr\"]),\n",
    "        loss=\"binary_crossentropy\",\n",
    "        metrics=[\"AUC\"]\n",
    "    )\n",
    "    model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_per_epoch = 560000 // 16 * len(train_files) // Params[\"batch_size\"]\n",
    "validation_steps = 560000 // 16 * len(val_files) // Params[\"batch_size\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the best performing model architecture. It was originally based on the architecture described in [this paper](https://arxiv.org/abs/1908.03151) and [this paper](https://arxiv.org/abs/2012.13101), but altered for higher performance in low SNR situations. The model in this form has excessive complexity and it should be possible to slim it down without sacrificing too much performance. The main performance-boosting change was increasing the layer count in the second convolution block to 3 instead of the 1 proposed in the papers."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-17T17:22:54.953060Z",
     "iopub.status.busy": "2021-09-17T17:22:54.952812Z",
     "iopub.status.idle": "2021-09-17T17:22:54.957958Z",
     "shell.execute_reply": "2021-09-17T17:22:54.957019Z",
     "shell.execute_reply.started": "2021-09-17T17:22:54.953033Z"
    }
   },
   "source": [
    "#best\n",
    "from tensorflow.keras import Sequential, layers\n",
    "with strategy.scope():\n",
    "    model = Sequential([\n",
    "        layers.Conv1D(filters=256, activation=\"relu\", kernel_size=3, padding=\"causal\",input_shape=[4096,3]),\n",
    "        layers.Conv1D(filters=256, activation=\"relu\", kernel_size=6, padding=\"causal\"),\n",
    "        layers.Conv1D(filters=256, activation=\"relu\", kernel_size=6, padding=\"causal\"),\n",
    "        \n",
    "        layers.MaxPool1D(pool_size=2),\n",
    "        layers.Activation(\"relu\"),\n",
    "        \n",
    "        layers.Conv1D(filters=64, activation=\"relu\", kernel_size=8, padding=\"causal\"),\n",
    "        layers.Conv1D(filters=128, activation=\"relu\", kernel_size=8, padding=\"causal\"),\n",
    "        layers.Conv1D(filters=128, activation=\"relu\", kernel_size=8, padding=\"causal\"),\n",
    "        layers.MaxPool1D(pool_size=4),\n",
    "        layers.Dropout(0.4),\n",
    "        layers.Activation(\"relu\"),\n",
    "        \n",
    "        layers.Conv1D(filters=128, activation=\"relu\", kernel_size=8, padding=\"causal\"),\n",
    "        layers.Conv1D(filters=128, activation=\"relu\",kernel_size=8, padding=\"causal\"),\n",
    "        layers.Conv1D(filters=128, activation=\"relu\",kernel_size=8, padding=\"causal\"),\n",
    "        \n",
    "        layers.MaxPool1D(pool_size=4),\n",
    "        layers.Activation(\"relu\"),\n",
    "        \n",
    "        layers.Conv1D(filters=256, activation=\"relu\", kernel_size=8, padding=\"causal\"),\n",
    "        layers.Conv1D(filters=256, activation=\"relu\",kernel_size=8, padding=\"causal\"),\n",
    "        layers.Conv1D(filters=256, activation=\"relu\",kernel_size=8, padding=\"causal\"),\n",
    "        \n",
    "        layers.MaxPool1D(pool_size=4),\n",
    "        layers.Activation(\"relu\"),\n",
    "        \n",
    "        layers.Flatten(),\n",
    "        layers.Dense(128, activation=\"relu\"),\n",
    "        layers.Dense(64, activation=\"relu\"),\n",
    "        layers.Dense(32, activation=\"relu\"),\n",
    "        \n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(1),\n",
    "        layers.Activation(\"sigmoid\", dtype=\"float32\")\n",
    "    ])\n",
    "    \n",
    "    lr_decayed_fn = tf.keras.experimental.CosineDecay(\n",
    "        1e-3,\n",
    "        steps_per_epoch\n",
    "    )\n",
    "    \n",
    "    opt = tf.keras.optimizers.Adam(learning_rate = Params[\"lr\"])\n",
    "\n",
    "    #opt = tfa.optimizers.AdamW(lr_decayed_fn, learning_rate = Params[\"lr\"])\n",
    "    model.compile(\n",
    "        opt,\n",
    "        loss=\"binary_crossentropy\",\n",
    "        metrics=[\"AUC\"]\n",
    "    )\n",
    "    model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Altered version of the above model, that I'm currently testing"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from tensorflow.keras import Sequential, layers\n",
    "with strategy.scope():\n",
    "    model = Sequential([\n",
    "        tf.keras.Input(shape=[4096,3]),\n",
    "        layers.Conv1D(filters=256, activation=\"elu\", kernel_size=3, padding=\"same\"),\n",
    "        layers.Conv1D(filters=256, activation=\"elu\", kernel_size=6, padding=\"same\"),\n",
    "        layers.Conv1D(filters=256, activation=\"elu\", kernel_size=6, padding=\"same\"),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPool1D(pool_size=2),\n",
    "        layers.Activation(\"elu\"),\n",
    "        \n",
    "        layers.Conv1D(filters=64, activation=\"elu\", kernel_size=8, padding=\"same\"),\n",
    "        layers.Conv1D(filters=128, activation=\"elu\", kernel_size=8, padding=\"same\"),\n",
    "        layers.Conv1D(filters=128, activation=\"elu\", kernel_size=8, padding=\"same\"),\n",
    "        layers.MaxPool1D(pool_size=4),\n",
    "        layers.BatchNormalization(),\n",
    "        \n",
    "        layers.Dropout(0.4),\n",
    "        layers.Activation(\"elu\"),\n",
    "        \n",
    "        layers.Conv1D(filters=128, activation=\"elu\", kernel_size=8, padding=\"same\"),\n",
    "        layers.Conv1D(filters=128, activation=\"elu\",kernel_size=8, padding=\"same\"),\n",
    "        layers.Conv1D(filters=128, activation=\"elu\",kernel_size=8, padding=\"same\"),\n",
    "        layers.BatchNormalization(),\n",
    "        \n",
    "        layers.MaxPool1D(pool_size=4),\n",
    "        layers.Activation(\"elu\"),\n",
    "        \n",
    "        layers.Conv1D(filters=256, activation=\"elu\", kernel_size=8, padding=\"same\"),\n",
    "        layers.Conv1D(filters=256, activation=\"elu\",kernel_size=8, padding=\"same\"),\n",
    "        layers.Conv1D(filters=256, activation=\"elu\",kernel_size=8, padding=\"same\"),\n",
    "        layers.BatchNormalization(),\n",
    "        \n",
    "        layers.MaxPool1D(pool_size=4),\n",
    "        layers.Activation(\"elu\"),\n",
    "        \n",
    "        layers.Flatten(),\n",
    "        layers.Dense(128, activation=\"elu\"),\n",
    "        layers.Dropout(0.4),\n",
    "        layers.Dense(64, activation=\"elu\"),\n",
    "        layers.Dropout(0.4),\n",
    "        layers.Dense(32, activation=\"elu\"),\n",
    "        \n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(1, kernel_constraint=tf.keras.constraints.MinMaxNorm(min_value=0.001, max_value=0.999),\n",
    "                     kernel_initializer=tf.keras.initializers.RandomUniform(minval=0.3, maxval=0.4),\n",
    "                     dtype=tf.float32\n",
    "                    ),\n",
    "#         layers.Activation(\"sigmoid\", dtype=\"float32\")\n",
    "    ])\n",
    "    \n",
    "    lr_decayed_fn = tf.keras.experimental.CosineDecay(\n",
    "        1e-3,\n",
    "        steps_per_epoch\n",
    "    )\n",
    "    \n",
    "    opt = tf.keras.optimizers.Adam(learning_rate = Params[\"lr\"])\n",
    "    loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "    AUC = tf.keras.metrics.AUC(from_logits=True)\n",
    "    \n",
    "    #opt = tfa.optimizers.AdamW(lr_decayed_fn, learning_rate = Params[\"lr\"])\n",
    "    model.compile(\n",
    "        opt,\n",
    "        loss=loss,\n",
    "        metrics=[AUC]\n",
    "    )\n",
    "    model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load a trained version of the filter, to use for fine-tuning. The current detection model is not suited well as a head for this filter, since it is far to complex for such a task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 4096, 12)          156       \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 4096, 12, 1)       0         \n",
      "_________________________________________________________________\n",
      "time_distributed (TimeDistri (None, 4096, 12, 32)      128       \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 4096, 6, 32)       0         \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, 4096, 6, 16)       1552      \n",
      "_________________________________________________________________\n",
      "time_distributed_3 (TimeDist (None, 4096, 96)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 4096, 256)         231424    \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 4096, 256)         395264    \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 4096, 256)         395264    \n",
      "_________________________________________________________________\n",
      "time_distributed_4 (TimeDist (None, 4096, 3)           771       \n",
      "=================================================================\n",
      "Total params: 2,049,118\n",
      "Trainable params: 1,024,559\n",
      "Non-trainable params: 1,024,559\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "pre_filter = tf.keras.models.load_model(\"model5.h5\")\n",
    "pre_filter.trainable=False\n",
    "pre_filter.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "less complex model with filter for fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\apist\\anaconda3\\envs\\g2net-tf\\lib\\site-packages\\keras\\layers\\normalization\\batch_normalization.py:520: _colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "sequential (Sequential)      (None, 4096, 3)           1024559   \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 4096, 192)         12480     \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 4096, 192)         768       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 4096, 192)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 4096, 64)          393280    \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 512, 64)           0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 512, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 512, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 512, 128)          262272    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 512, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 512, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 512, 128)          262272    \n",
      "_________________________________________________________________\n",
      "average_pooling1d (AveragePo (None, 85, 128)           0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 85, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 85, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 85, 256)           524544    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 85, 256)           1024      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 85, 256)           0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 21760)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                1392704   \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 65        \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 3,879,920\n",
      "Trainable params: 2,853,569\n",
      "Non-trainable params: 1,026,351\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import Sequential, layers\n",
    "with strategy.scope():\n",
    "    model = Sequential([\n",
    "        tf.keras.Input(shape=([4096,3])),\n",
    "        pre_filter,\n",
    "        layers.Conv1D(filters=64*3, activation=None, kernel_size=64, padding=\"causal\",input_shape=[4096,3], groups=3),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Activation(\"elu\"),\n",
    "        \n",
    "        layers.Conv1D(filters=64, activation=None, kernel_size=32, padding=\"causal\"),\n",
    "        layers.MaxPool1D(pool_size=8),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Activation(\"elu\"),\n",
    "        \n",
    "        layers.Conv1D(filters=128, activation=None,kernel_size=32, padding=\"causal\"),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Activation(\"elu\"),\n",
    "        \n",
    "        layers.Conv1D(filters=128, activation=None,kernel_size=16, padding=\"causal\"),\n",
    "        layers.AvgPool1D(pool_size=6),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Activation(\"elu\"),\n",
    "        \n",
    "        layers.Conv1D(filters=256, activation=\"relu\",kernel_size=16, padding=\"causal\"),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Activation(\"elu\"),\n",
    "        \n",
    "        \n",
    "        layers.Flatten(),\n",
    "        layers.Dense(64, activation=None),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.4),\n",
    "        layers.Activation(\"elu\"),\n",
    "        \n",
    "        layers.Dense(64, activation=None),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.4),\n",
    "        layers.Activation(\"elu\"),\n",
    "        \n",
    "        \n",
    "        layers.Dropout(0.4),\n",
    "        layers.Dense(1, kernel_constraint=tf.keras.constraints.MinMaxNorm(min_value=0.001, max_value=0.999),\n",
    "                     kernel_initializer=tf.keras.initializers.RandomUniform(minval=0.3, maxval=0.4)\n",
    "                    ),\n",
    "        layers.Activation(\"sigmoid\", dtype=\"float32\")\n",
    "    ])\n",
    "    \n",
    "    lr_decayed_fn = tf.keras.experimental.CosineDecay(\n",
    "        1e-3,\n",
    "        steps_per_epoch\n",
    "    )\n",
    "    opt = tfa.optimizers.Lookahead(\n",
    "        tfa.optimizers.AdamW(lr_decayed_fn, learning_rate = Params[\"lr\"]),\n",
    "        sync_period=6\n",
    "    )\n",
    "\n",
    "    loss = tf.keras.losses.BinaryCrossentropy(from_logits=False)\n",
    "    AUC = tf.keras.metrics.AUC(from_logits=True)\n",
    "\n",
    "    #opt = tfa.optimizers.AdamW(lr_decayed_fn, learning_rate = Params[\"lr\"])\n",
    "    model.compile(\n",
    "        opt,\n",
    "        loss=loss,\n",
    "        metrics=[AUC]\n",
    "    )\n",
    "    model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get_lr_callback()\n",
    "\n",
    "This function creates a callback to alter the learning rate in a way that has been shown to be advantageous. This is an altered version of the one seen in [this notebook](https://www.kaggle.com/miklgr500/cqt-g2net-efficientnetb7-tpu-training-w-b#Build-Model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lr_callback(batch_size=8):\n",
    "    lr_start = Params[\"lr\"]\n",
    "    lr_max = 0.0000015 * batch_size\n",
    "    lr_min = 1e-7\n",
    "    lr_ramp_ep = 3\n",
    "    lr_sus_ep = 0\n",
    "    lr_decay = 0.7\n",
    "    \n",
    "    def lrfn(epoch):\n",
    "        initial_epochs = 4\n",
    "        \n",
    "        epoch = epoch - initial_epochs\n",
    "        if epoch < -1 * initial_epochs + 2:\n",
    "            return lr_start/10\n",
    "        elif epoch < 0:\n",
    "            lr = lr_start\n",
    "        elif epoch < lr_ramp_ep:\n",
    "            lr = (lr_max - lr_start) / lr_ramp_ep * epoch + lr_start\n",
    "        elif epoch < lr_ramp_ep + lr_sus_ep:\n",
    "            lr = lr_max\n",
    "        else:\n",
    "            lr = (lr_max - lr_min) * lr_decay**(epoch - lr_ramp_ep - lr_sus_ep) + lr_min\n",
    "        return lr\n",
    "    lr_callback = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose = True)\n",
    "    return lr_callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Learning Rate Schedule with batch size of 256')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def lrfn(epoch):\n",
    "    lr_start = Params[\"lr\"]\n",
    "    lr_max = 0.0000015 * Params[\"batch_size\"]\n",
    "    lr_min = 1e-7\n",
    "    lr_ramp_ep = 3\n",
    "    lr_sus_ep = 0\n",
    "    lr_decay = 0.7\n",
    "    initial_epochs = 4\n",
    "\n",
    "    epoch = epoch - initial_epochs\n",
    "    if epoch < -1 * initial_epochs + 2:\n",
    "        return lr_start/10\n",
    "    elif epoch < 0:\n",
    "        lr = lr_start\n",
    "    elif epoch < lr_ramp_ep:\n",
    "        lr = (lr_max - lr_start) / lr_ramp_ep * epoch + lr_start\n",
    "    elif epoch < lr_ramp_ep + lr_sus_ep:\n",
    "        lr = lr_max\n",
    "    else:\n",
    "        lr = (lr_max - lr_min) * lr_decay**(epoch - lr_ramp_ep - lr_sus_ep) + lr_min\n",
    "    return lr\n",
    "\n",
    "lrs = []\n",
    "for epoch in range(30):\n",
    "    lrs.append(lrfn(epoch))\n",
    "    \n",
    "plt.figure(figsize=(12,5))\n",
    "plt.plot(lrs)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.title(\"Learning Rate Schedule with batch size of 256\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is trained at 1/10 of `Params[\"lr\"]`, for which 1e-4 is recommended for the best performing architecture described above, since the models don't always converge when starting out at 1e-4. This was not used when training the model with the included filter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-17T17:22:54.960073Z",
     "iopub.status.busy": "2021-09-17T17:22:54.959840Z",
     "iopub.status.idle": "2021-09-17T17:22:54.971237Z",
     "shell.execute_reply": "2021-09-17T17:22:54.970202Z",
     "shell.execute_reply.started": "2021-09-17T17:22:54.960046Z"
    }
   },
   "outputs": [],
   "source": [
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor=\"val_loss\", factor=0.2,\n",
    "    patience=6, min_lr = 1e-7,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    min_delta = 0.0003,\n",
    "    mode=\"min\",\n",
    "    patience=10\n",
    ")\n",
    "\n",
    "model_checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    f\"{MDL_PATH}/model_{Params['version']:03}.h5\",\n",
    "    monitor=\"val_loss\",\n",
    "    verbose=0,\n",
    "    save_best_only=True,\n",
    "    save_weight_only=False,\n",
    "    mode=\"min\",\n",
    "    save_freq=\"epoch\",\n",
    "    \n",
    ")\n",
    "\n",
    "callbacks=[get_lr_callback(Params[\"batch_size\"]) ,reduce_lr, early_stop, model_checkpoint]\n",
    "# callbacks=[reduce_lr, early_stop,model_checkpoint]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "### Train Head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-17T17:22:54.972832Z",
     "iopub.status.busy": "2021-09-17T17:22:54.972552Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1914 steps, validate on 273 steps\n",
      "\n",
      "Epoch 00001: LearningRateScheduler setting learning rate to 1e-05.\n",
      "Epoch 1/35\n",
      "1656/1914 [========================>.....] - ETA: 2:11 - batch: 827.5000 - size: 1.0000 - loss: 0.5828 - auc: 0.7427"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_ds, validation_data = val_ds, epochs = Params[\"epochs\"], shuffle=False,\n",
    "                    steps_per_epoch = steps_per_epoch, validation_steps=validation_steps,\n",
    "                    verbose=1, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train filter\n",
    "\n",
    "Now training is enabled on the filter itself. The filter requires a much higher learning rate than the detection network, so the layers of the detection network are not trained until the filter converges. Once the filter converges, the whole network can be trained at the same time. The reason the filter needs to be trained at such a high learning rate instead of just fine-tuning it, is that the pre-processing of the currently finished synthetic datasets used to train the filter is unfortunately different to the pre-processing applied to the Kaggle dataset:\n",
    "\n",
    "* in the synthetic dataset, the signal was whitened and bandpassed over a signal length of 8s, then cut down to 2s. This means the data corruption of the filtering process was cut out of the signal. Due to the fact that in the Kaggle dataset only 2s of time is available for each sample, the filters were applied to that time-frame, letting the data corruption caused by the filters influence the whole time series.\n",
    "\n",
    "* additionally the parameters of the filters were different on both datasets. The whitening process, for example used a window length of 4s on the synthetic dataset, whereas a 0.5s window was used on the Kaggle dataset.\n",
    "\n",
    "* The reported signal to noise ratio(SNR) of the tool used to create the synthetic datasets is either incorrect or the SNR of the Kaggle dataset is very low. This can be seen because detection models without filter, which were only trained on the pre-processed Kaggle dataset perform very highly on the synthetic datasets (up to a area under curve (AUC) score of 0.95, compared to 0.85 on the datasets used for training), which have never been seen by the model. This implies that either for reasons of SNR inconsistencies or because of data corruption by the filters, the Kaggle dataset is much harder than the synthetic ones, which makes the filter not well-posed on the Kaggle dataset, which necessitates a reasonably high learning rate. Additionally the learning rate required by the filter is in general 2 orders of magnitude higher than that of the detection network. In general the tool used to create the synthetic datasets reports a SNR of around 6 which is very low and should not lead to such high AUC scores. Additionally the way the signals are treated by the tool should lead to a consistent SNR at any simulated distance between detector and event, but in practice the pre-trained detection models perform worse on datasets with a higher distance and the same reported SNR.\n",
    "\n",
    "To alleviate these issues new synthetic datasets are currently being created without any pre-processing and at different distances to be able to apply the same pre-processing pipeline to the samples as is used on the Kaggle datasets, so that the filter can be trained on a comparable dataset to the Kaggle one, hopefully leading to a better posed filter.\n",
    "\n",
    "The reason for creating synthetic datasets for training the filter is that the Kaggle dataset only has a binary target, either there is a gravitational wave in the noise or not. To be able to train a filter to recreate the wavelet pattern, the shape of the wavelet hast to be known."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor=\"val_loss\", factor=0.2,\n",
    "    patience=6, min_lr = 0.0000001,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    min_delta = 0.0003,\n",
    "    mode=\"min\",\n",
    "    patience=10\n",
    ")\n",
    "\n",
    "model_checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    f\"{MDL_PATH}/model_{Params['version']:03}_2.h5\",\n",
    "    monitor=\"val_loss\",\n",
    "    verbose=0,\n",
    "    save_best_only=True,\n",
    "    save_weight_only=False,\n",
    "    mode=\"auto\",\n",
    "    save_freq=\"epoch\",\n",
    "    \n",
    ")\n",
    "\n",
    "# callbacks=[get_lr_callback(Params[\"batch_size\"]) ,reduce_lr, early_stop, model_checkpoint]\n",
    "callbacks=[reduce_lr, early_stop,model_checkpoint]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Enable Training on Filter\n",
    "\n",
    "only the layers of the encoder are trained here. This is done, because the goal is to get the encoder to encode the same way it did on the synthetic training datasets and also because the LSTM layers of the decoder part of the filter take a lot of training time, especially on a TPU runtime, where the CUDA implementation does not work and necessitates the use of the CPU."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "with strategy.scope():\n",
    "    \n",
    "    for layer in model.layers:\n",
    "        layer.trainable=False\n",
    "    pre_filter.trainable=True\n",
    "    for i,layer in enumerate(pre_filter.layers[6:]):\n",
    "        print(i, layer)\n",
    "        layer.trainable=False\n",
    "    \n",
    "\n",
    "    opt = tfa.optimizers.Lookahead(\n",
    "#         tfa.optimizers.AdamW(lr_decayed_fn, learning_rate = 1e-3),\n",
    "        tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "        sync_period=6\n",
    "    )\n",
    "    loss = tf.keras.losses.BinaryCrossentropy(from_logits=False)\n",
    "    AUC = tf.keras.metrics.AUC()\n",
    "\n",
    "\n",
    "    model.compile(\n",
    "        opt,\n",
    "        loss=loss,\n",
    "        metrics=[AUC]\n",
    "    )\n",
    "    model.summary()\n",
    "    # model is loaded from best checkpoint in case of overfitting in later epochs\n",
    "    model.load_weights(f\"{MDL_PATH}/model_{Params['version']:03}.h5\")\n",
    "    "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "history2 = model.fit(train_ds, validation_data = val_ds, epochs = Params[\"epochs\"], shuffle=True,\n",
    "                    steps_per_epoch = steps_per_epoch, validation_steps=validation_steps,\n",
    "                    verbose=1, callbacks=callbacks)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-tuning\n",
    "\n",
    "After the filter converges with the pre-trained Detection model, the complete model can now be trained at a lower learning rate, although at the time of writing the detection model is still much to complex, making overfitting a significant problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    pre_filter.trainable=False\n",
    "    for layer in model.layers:\n",
    "        layer.trainable=True\n",
    "    for layer in pre_filter.layers:\n",
    "        layer.trainable=True\n",
    "    \n",
    "#     for i,layer in enumerate(pre_filter.layers[6:]):\n",
    "#         print(i, layer)\n",
    "#         layer.trainable=False\n",
    "\n",
    "    opt = tfa.optimizers.Lookahead(\n",
    "#         tfa.optimizers.AdamW(lr_decayed_fn, learning_rate = 1e-4),\n",
    "        tf.keras.optimizers.Adam(learning_rate=5e-6),\n",
    "        sync_period=6\n",
    "    )\n",
    "    loss = tf.keras.losses.BinaryCrossentropy(from_logits=False)\n",
    "    AUC = tf.keras.metrics.AUC()\n",
    "\n",
    "\n",
    "    model.compile(\n",
    "        opt,\n",
    "        loss=loss,\n",
    "        metrics=[AUC]\n",
    "    )\n",
    "    model.summary()\n",
    "    # model is loaded from checkpoint to get the best performing model\n",
    "    # hopefully alleviating some overfitting\n",
    "#     model.load_weights(f\"{MDL_PATH}/model_{Params['version']:03}.h5\".replace(f\"{VER:03}\",\"446\"))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history2 = model.fit(train_ds, validation_data = val_ds, epochs = Params[\"epochs\"], shuffle=True,\n",
    "                    steps_per_epoch = steps_per_epoch, validation_steps=validation_steps,\n",
    "                    verbose=1, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "\n",
    "### Log model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "historyFrame = pd.DataFrame(history.history)\n",
    "historyFrame[[\"auc\", \"val_auc\"]].plot()\n",
    "historyFrame[[\"loss\", \"val_loss\"]].plot()\n",
    "historyFrame.to_csv(f\"{MDL_PATH}/history_mdl{Params['version']:03}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historyFrame2 = pd.DataFrame(history2.history)\n",
    "historyFrame2[[\"auc_1\", \"val_auc_1\"]].plot()\n",
    "historyFrame2[[\"loss\", \"val_loss\"]].plot()\n",
    "historyFrame2.to_csv(f\"{MDL_PATH}/history_mdl{Params['version']:03}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "historyFrame"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "historyFrame2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_epoch = historyFrame.val_auc.argmax()\n",
    "best_loss = historyFrame.iloc[best_epoch].loss\n",
    "best_auc = historyFrame.iloc[best_epoch].val_auc\n",
    "print(\"best epoch:\", best_epoch,\n",
    "      \"| best loss:\", best_loss,\n",
    "      \"| best auc:\", best_auc\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_epoch = historyFrame2.val_auc_1.argmax()\n",
    "best_loss = historyFrame2.iloc[best_epoch].loss\n",
    "best_auc = historyFrame2.iloc[best_epoch].val_auc_1\n",
    "print(\"best epoch:\", best_epoch,\n",
    "      \"| best loss:\", best_loss,\n",
    "      \"| best auc:\", best_auc\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = Params.copy()\n",
    "result[\"bavg_epoch\"] = int(best_epoch)\n",
    "result[\"bavg_loss\"] = float(best_loss)\n",
    "result[\"bavg_auc\"] = float(best_auc)\n",
    "with open(f\"{MDL_PATH}/params.json\", \"w\") as file:\n",
    "    json.dump(result, file)\n",
    "\n",
    "if not os.path.exists(f\"{MDLS_PATH}/results.csv\"):\n",
    "    df_save = pd.DataFrame(result, index=[0])\n",
    "    df_save.to_csv(f\"{MDLS_PATH}/results.csv\")\n",
    "else:\n",
    "    df_old = pd.read_csv(f\"{MDLS_PATH}/results.csv\", index_col=0)\n",
    "    df_save = pd.DataFrame(result, index = [df_old.index.max() + 1])\n",
    "    df_save = df_old.append(df_save, ignore_index=True)\n",
    "    df_save.to_csv(f\"{MDLS_PATH}/results.csv\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(f\"{MDLS_PATH}/results.csv\",index_col=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_ds, val_ds\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_scores = []\n",
    "with strategy.scope():\n",
    "    model2 = tf.keras.models.load_model(f\"{MDL_PATH}/model_{Params['version']:03}.h5\")\n",
    "n_vals = len(val_files) // len(tfrec_folders)\n",
    "for i in range(len(tfrec_folders)):\n",
    "    files = val_files[i * n_vals: (i + 1)*n_vals] \n",
    "    val_ds = load_dataset(files, shuffle=False, cache=False, ordered=True, repeat=False)\n",
    "    history = model.evaluate(val_ds, steps = 35000 * n_vals // Params[\"batch_size\"])\n",
    "    prediction_scores.append(history[1])\n",
    "print(prediction_scores)\n",
    "best_pred = np.array(prediction_scores).argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = load_dataset(test_files[best_pred], cache=False, shuffle=False, ordered=True, labeled=False, repeat=False, return_labels=False)\n",
    "test_prediction = model.predict(test_set)\n",
    "sub = pd.read_csv(\"../input/g2net-gravitational-wave-detection/sample_submission.csv\")\n",
    "sub.target = test_prediction.flatten()\n",
    "sub.to_csv(f\"{MDL_PATH}/submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
