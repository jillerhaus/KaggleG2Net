{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-15T15:02:24.741032Z",
     "iopub.status.busy": "2021-09-15T15:02:24.740348Z",
     "iopub.status.idle": "2021-09-15T15:02:24.76936Z",
     "shell.execute_reply": "2021-09-15T15:02:24.768408Z",
     "shell.execute_reply.started": "2021-09-15T15:02:24.740923Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KAGGLE: False\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "KAGGLE = True\n",
    "if os.name == \"nt\":\n",
    "    KAGGLE = False\n",
    "print(f\"KAGGLE: {KAGGLE}\")\n",
    "if not KAGGLE:\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-15T15:02:24.771135Z",
     "iopub.status.busy": "2021-09-15T15:02:24.770889Z",
     "iopub.status.idle": "2021-09-15T15:02:31.370857Z",
     "shell.execute_reply": "2021-09-15T15:02:31.369919Z",
     "shell.execute_reply.started": "2021-09-15T15:02:24.771106Z"
    }
   },
   "outputs": [],
   "source": [
    "# general\n",
    "import warnings\n",
    "import sklearn.exceptions\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=sklearn.exceptions.UndefinedMetricWarning)\n",
    "\n",
    "from glob import glob\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from IPython.core.display import display, HTML\n",
    "if KAGGLE:\n",
    "    from kaggle_datasets import KaggleDatasets\n",
    "\n",
    "# ML\n",
    "\n",
    "# DL\n",
    "import tensorflow as tf\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-15T15:02:31.372548Z",
     "iopub.status.busy": "2021-09-15T15:02:31.3722Z",
     "iopub.status.idle": "2021-09-15T15:02:31.385729Z",
     "shell.execute_reply": "2021-09-15T15:02:31.384962Z",
     "shell.execute_reply.started": "2021-09-15T15:02:31.372518Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# tf.compat.v1.disable_eager_execution()\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))\n",
    "%matplotlib inline\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-15T15:02:31.388574Z",
     "iopub.status.busy": "2021-09-15T15:02:31.387748Z",
     "iopub.status.idle": "2021-09-15T15:02:31.395949Z",
     "shell.execute_reply": "2021-09-15T15:02:31.39525Z",
     "shell.execute_reply.started": "2021-09-15T15:02:31.388533Z"
    }
   },
   "outputs": [],
   "source": [
    "def auto_select_accelerator():\n",
    "    TPU_DETECTED = False\n",
    "    try:\n",
    "        tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "        tf.config.experimental_connect_to_cluster(tpu)\n",
    "        tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "        strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "        tf.keras.mixed_precision.set_global_policy(\"mixed_bfloat16\")\n",
    "        print(f\"Running on TPU: {tpu.master()}\")\n",
    "        TPU_DETECTED = True\n",
    "    except ValueError:\n",
    "        strategy = tf.distribute.get_strategy()\n",
    "        tf.keras.mixed_precision.set_global_policy(\"mixed_float16\")\n",
    "    num_replicas = strategy.num_replicas_in_sync\n",
    "    print(f\"Running on {num_replicas} replica{'s' if num_replicas > 1 else ''}\")\n",
    "    return strategy, TPU_DETECTED, num_replicas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-15T15:02:31.397819Z",
     "iopub.status.busy": "2021-09-15T15:02:31.397375Z",
     "iopub.status.idle": "2021-09-15T15:02:31.4092Z",
     "shell.execute_reply": "2021-09-15T15:02:31.408603Z",
     "shell.execute_reply.started": "2021-09-15T15:02:31.397773Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lr</th>\n",
       "      <th>version</th>\n",
       "      <th>train_mode</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>epochs</th>\n",
       "      <th>bavg_epoch</th>\n",
       "      <th>bavg_loss</th>\n",
       "      <th>bavg_auc</th>\n",
       "      <th>changelog</th>\n",
       "      <th>seed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00100</td>\n",
       "      <td>1</td>\n",
       "      <td>full</td>\n",
       "      <td>256</td>\n",
       "      <td>60</td>\n",
       "      <td>16</td>\n",
       "      <td>0.451789</td>\n",
       "      <td>0.838065</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00100</td>\n",
       "      <td>2</td>\n",
       "      <td>test</td>\n",
       "      <td>256</td>\n",
       "      <td>60</td>\n",
       "      <td>13</td>\n",
       "      <td>0.449180</td>\n",
       "      <td>0.822957</td>\n",
       "      <td>moved all relu layers before the pooling layers</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00100</td>\n",
       "      <td>3</td>\n",
       "      <td>full</td>\n",
       "      <td>256</td>\n",
       "      <td>60</td>\n",
       "      <td>20</td>\n",
       "      <td>0.442866</td>\n",
       "      <td>0.837724</td>\n",
       "      <td>tried on large ds, since hight overfitting</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00100</td>\n",
       "      <td>5</td>\n",
       "      <td>test</td>\n",
       "      <td>256</td>\n",
       "      <td>60</td>\n",
       "      <td>13</td>\n",
       "      <td>0.449431</td>\n",
       "      <td>0.822973</td>\n",
       "      <td>added second layer to first block or reference</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00100</td>\n",
       "      <td>6</td>\n",
       "      <td>test</td>\n",
       "      <td>256</td>\n",
       "      <td>30</td>\n",
       "      <td>9</td>\n",
       "      <td>0.442229</td>\n",
       "      <td>0.820143</td>\n",
       "      <td>added relu activations to all conv layers</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.00100</td>\n",
       "      <td>9</td>\n",
       "      <td>test</td>\n",
       "      <td>256</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>0.480765</td>\n",
       "      <td>0.812309</td>\n",
       "      <td>set all pool sizes to 1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.00100</td>\n",
       "      <td>11</td>\n",
       "      <td>test</td>\n",
       "      <td>256</td>\n",
       "      <td>30</td>\n",
       "      <td>8</td>\n",
       "      <td>0.438630</td>\n",
       "      <td>0.819107</td>\n",
       "      <td>set all pool sizes to 8</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.00100</td>\n",
       "      <td>13</td>\n",
       "      <td>test</td>\n",
       "      <td>256</td>\n",
       "      <td>30</td>\n",
       "      <td>12</td>\n",
       "      <td>0.448575</td>\n",
       "      <td>0.820421</td>\n",
       "      <td>added second layer to first block with small k...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.00010</td>\n",
       "      <td>14</td>\n",
       "      <td>test</td>\n",
       "      <td>256</td>\n",
       "      <td>30</td>\n",
       "      <td>12</td>\n",
       "      <td>0.457616</td>\n",
       "      <td>0.820876</td>\n",
       "      <td>added second layer to first block with small k...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.00010</td>\n",
       "      <td>17</td>\n",
       "      <td>test</td>\n",
       "      <td>64</td>\n",
       "      <td>30</td>\n",
       "      <td>6</td>\n",
       "      <td>0.475783</td>\n",
       "      <td>0.814108</td>\n",
       "      <td>trial of completely different achitecture</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.00010</td>\n",
       "      <td>33</td>\n",
       "      <td>full</td>\n",
       "      <td>64</td>\n",
       "      <td>60</td>\n",
       "      <td>13</td>\n",
       "      <td>0.457444</td>\n",
       "      <td>0.825847</td>\n",
       "      <td>trial of completely different achitecture</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.00500</td>\n",
       "      <td>43</td>\n",
       "      <td>full</td>\n",
       "      <td>64</td>\n",
       "      <td>60</td>\n",
       "      <td>43</td>\n",
       "      <td>0.452197</td>\n",
       "      <td>0.836913</td>\n",
       "      <td>trial of completely different achitecture</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.00010</td>\n",
       "      <td>47</td>\n",
       "      <td>full</td>\n",
       "      <td>64</td>\n",
       "      <td>60</td>\n",
       "      <td>9</td>\n",
       "      <td>0.452419</td>\n",
       "      <td>0.836464</td>\n",
       "      <td>model before was standard model with 0.001 no ...</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.00010</td>\n",
       "      <td>55</td>\n",
       "      <td>full</td>\n",
       "      <td>64</td>\n",
       "      <td>60</td>\n",
       "      <td>4</td>\n",
       "      <td>0.451851</td>\n",
       "      <td>0.833302</td>\n",
       "      <td>removed dropout layer in conv</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.00010</td>\n",
       "      <td>57</td>\n",
       "      <td>full</td>\n",
       "      <td>128</td>\n",
       "      <td>20</td>\n",
       "      <td>9</td>\n",
       "      <td>0.434063</td>\n",
       "      <td>0.835922</td>\n",
       "      <td>before: removed 2 fully connected layers. now:...</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.00010</td>\n",
       "      <td>61</td>\n",
       "      <td>full</td>\n",
       "      <td>256</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.483809</td>\n",
       "      <td>0.824025</td>\n",
       "      <td>removed dropout, flatten, added lstm</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.00010</td>\n",
       "      <td>64</td>\n",
       "      <td>full</td>\n",
       "      <td>256</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>0.465674</td>\n",
       "      <td>0.824023</td>\n",
       "      <td>removed 2 layers in larger block</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.00010</td>\n",
       "      <td>66</td>\n",
       "      <td>full</td>\n",
       "      <td>256</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>0.460225</td>\n",
       "      <td>0.827190</td>\n",
       "      <td>added back one layer</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.00010</td>\n",
       "      <td>67</td>\n",
       "      <td>full</td>\n",
       "      <td>256</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>0.454083</td>\n",
       "      <td>0.827726</td>\n",
       "      <td>third layer</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.00010</td>\n",
       "      <td>68</td>\n",
       "      <td>full</td>\n",
       "      <td>256</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>0.455897</td>\n",
       "      <td>0.827700</td>\n",
       "      <td>doubled the first layer and added a second one...</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.00100</td>\n",
       "      <td>70</td>\n",
       "      <td>full</td>\n",
       "      <td>256</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>0.467193</td>\n",
       "      <td>0.832003</td>\n",
       "      <td>base model</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.00100</td>\n",
       "      <td>72</td>\n",
       "      <td>full</td>\n",
       "      <td>256</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>0.483452</td>\n",
       "      <td>0.824098</td>\n",
       "      <td>took out the fully connected layers before the...</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.00100</td>\n",
       "      <td>73</td>\n",
       "      <td>full</td>\n",
       "      <td>256</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>0.472798</td>\n",
       "      <td>0.830427</td>\n",
       "      <td>added back one fully connected layer</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.00010</td>\n",
       "      <td>75</td>\n",
       "      <td>full</td>\n",
       "      <td>256</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>0.454001</td>\n",
       "      <td>0.830381</td>\n",
       "      <td>doubled pool size, except for last, doubled nu...</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.00100</td>\n",
       "      <td>76</td>\n",
       "      <td>full</td>\n",
       "      <td>256</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>0.469206</td>\n",
       "      <td>0.832270</td>\n",
       "      <td>base model with same padding</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.00010</td>\n",
       "      <td>78</td>\n",
       "      <td>full</td>\n",
       "      <td>256</td>\n",
       "      <td>40</td>\n",
       "      <td>12</td>\n",
       "      <td>0.442443</td>\n",
       "      <td>0.841306</td>\n",
       "      <td>doubled last layer in all blocks. lr/10</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.00050</td>\n",
       "      <td>79</td>\n",
       "      <td>full</td>\n",
       "      <td>256</td>\n",
       "      <td>40</td>\n",
       "      <td>25</td>\n",
       "      <td>0.439258</td>\n",
       "      <td>0.842578</td>\n",
       "      <td>doubled last layer in all blocks doubled size ...</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.00050</td>\n",
       "      <td>83</td>\n",
       "      <td>full</td>\n",
       "      <td>256</td>\n",
       "      <td>40</td>\n",
       "      <td>27</td>\n",
       "      <td>0.439051</td>\n",
       "      <td>0.841536</td>\n",
       "      <td>added dropout layers to dense layers</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.00010</td>\n",
       "      <td>88</td>\n",
       "      <td>full</td>\n",
       "      <td>256</td>\n",
       "      <td>40</td>\n",
       "      <td>8</td>\n",
       "      <td>0.453092</td>\n",
       "      <td>0.834111</td>\n",
       "      <td>everything had 3 layers now and relu activation</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.00010</td>\n",
       "      <td>92</td>\n",
       "      <td>full</td>\n",
       "      <td>256</td>\n",
       "      <td>100</td>\n",
       "      <td>17</td>\n",
       "      <td>0.434836</td>\n",
       "      <td>0.832301</td>\n",
       "      <td>dropout layers</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.00010</td>\n",
       "      <td>110</td>\n",
       "      <td>full</td>\n",
       "      <td>256</td>\n",
       "      <td>100</td>\n",
       "      <td>11</td>\n",
       "      <td>0.470093</td>\n",
       "      <td>0.815836</td>\n",
       "      <td>dropout layers</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.00010</td>\n",
       "      <td>113</td>\n",
       "      <td>full</td>\n",
       "      <td>256</td>\n",
       "      <td>100</td>\n",
       "      <td>8</td>\n",
       "      <td>0.476270</td>\n",
       "      <td>0.813889</td>\n",
       "      <td>dropout layers</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.00002</td>\n",
       "      <td>119</td>\n",
       "      <td>full</td>\n",
       "      <td>256</td>\n",
       "      <td>100</td>\n",
       "      <td>36</td>\n",
       "      <td>0.463551</td>\n",
       "      <td>0.812370</td>\n",
       "      <td>new dataset using best model (base model with ...</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.00020</td>\n",
       "      <td>124</td>\n",
       "      <td>full</td>\n",
       "      <td>256</td>\n",
       "      <td>100</td>\n",
       "      <td>23</td>\n",
       "      <td>0.448196</td>\n",
       "      <td>0.827187</td>\n",
       "      <td>10x lr</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.00010</td>\n",
       "      <td>134</td>\n",
       "      <td>full</td>\n",
       "      <td>256</td>\n",
       "      <td>100</td>\n",
       "      <td>12</td>\n",
       "      <td>0.467185</td>\n",
       "      <td>0.826250</td>\n",
       "      <td>1/4 lr</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.00010</td>\n",
       "      <td>135</td>\n",
       "      <td>full</td>\n",
       "      <td>256</td>\n",
       "      <td>100</td>\n",
       "      <td>9</td>\n",
       "      <td>0.444164</td>\n",
       "      <td>0.848162</td>\n",
       "      <td>1/4 lr</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.00010</td>\n",
       "      <td>136</td>\n",
       "      <td>full</td>\n",
       "      <td>256</td>\n",
       "      <td>100</td>\n",
       "      <td>21</td>\n",
       "      <td>0.420500</td>\n",
       "      <td>0.854332</td>\n",
       "      <td>1/4 lr</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.00010</td>\n",
       "      <td>137</td>\n",
       "      <td>full</td>\n",
       "      <td>256</td>\n",
       "      <td>100</td>\n",
       "      <td>31</td>\n",
       "      <td>0.364450</td>\n",
       "      <td>0.876402</td>\n",
       "      <td>1/4 lr</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         lr  version train_mode  batch_size  epochs  bavg_epoch  bavg_loss  \\\n",
       "0   0.00100        1       full         256      60          16   0.451789   \n",
       "1   0.00100        2       test         256      60          13   0.449180   \n",
       "2   0.00100        3       full         256      60          20   0.442866   \n",
       "3   0.00100        5       test         256      60          13   0.449431   \n",
       "4   0.00100        6       test         256      30           9   0.442229   \n",
       "5   0.00100        9       test         256      30           4   0.480765   \n",
       "6   0.00100       11       test         256      30           8   0.438630   \n",
       "7   0.00100       13       test         256      30          12   0.448575   \n",
       "8   0.00010       14       test         256      30          12   0.457616   \n",
       "9   0.00010       17       test          64      30           6   0.475783   \n",
       "10  0.00010       33       full          64      60          13   0.457444   \n",
       "11  0.00500       43       full          64      60          43   0.452197   \n",
       "12  0.00010       47       full          64      60           9   0.452419   \n",
       "13  0.00010       55       full          64      60           4   0.451851   \n",
       "14  0.00010       57       full         128      20           9   0.434063   \n",
       "15  0.00010       61       full         256       3           2   0.483809   \n",
       "16  0.00010       64       full         256      10           7   0.465674   \n",
       "17  0.00010       66       full         256      10           6   0.460225   \n",
       "18  0.00010       67       full         256      10           7   0.454083   \n",
       "19  0.00010       68       full         256      10           7   0.455897   \n",
       "20  0.00100       70       full         256      10           9   0.467193   \n",
       "21  0.00100       72       full         256      10           9   0.483452   \n",
       "22  0.00100       73       full         256      10           9   0.472798   \n",
       "23  0.00010       75       full         256      10           9   0.454001   \n",
       "24  0.00100       76       full         256      10           6   0.469206   \n",
       "25  0.00010       78       full         256      40          12   0.442443   \n",
       "26  0.00050       79       full         256      40          25   0.439258   \n",
       "27  0.00050       83       full         256      40          27   0.439051   \n",
       "28  0.00010       88       full         256      40           8   0.453092   \n",
       "29  0.00010       92       full         256     100          17   0.434836   \n",
       "30  0.00010      110       full         256     100          11   0.470093   \n",
       "31  0.00010      113       full         256     100           8   0.476270   \n",
       "32  0.00002      119       full         256     100          36   0.463551   \n",
       "33  0.00020      124       full         256     100          23   0.448196   \n",
       "34  0.00010      134       full         256     100          12   0.467185   \n",
       "35  0.00010      135       full         256     100           9   0.444164   \n",
       "36  0.00010      136       full         256     100          21   0.420500   \n",
       "37  0.00010      137       full         256     100          31   0.364450   \n",
       "\n",
       "    bavg_auc                                          changelog  seed  \n",
       "0   0.838065                                                NaN   NaN  \n",
       "1   0.822957    moved all relu layers before the pooling layers   NaN  \n",
       "2   0.837724         tried on large ds, since hight overfitting   NaN  \n",
       "3   0.822973     added second layer to first block or reference   NaN  \n",
       "4   0.820143          added relu activations to all conv layers   NaN  \n",
       "5   0.812309                            set all pool sizes to 1   NaN  \n",
       "6   0.819107                            set all pool sizes to 8   NaN  \n",
       "7   0.820421  added second layer to first block with small k...   NaN  \n",
       "8   0.820876  added second layer to first block with small k...   NaN  \n",
       "9   0.814108          trial of completely different achitecture   NaN  \n",
       "10  0.825847          trial of completely different achitecture   NaN  \n",
       "11  0.836913          trial of completely different achitecture   NaN  \n",
       "12  0.836464  model before was standard model with 0.001 no ...  42.0  \n",
       "13  0.833302                      removed dropout layer in conv  42.0  \n",
       "14  0.835922  before: removed 2 fully connected layers. now:...  42.0  \n",
       "15  0.824025               removed dropout, flatten, added lstm  42.0  \n",
       "16  0.824023                   removed 2 layers in larger block  42.0  \n",
       "17  0.827190                               added back one layer  42.0  \n",
       "18  0.827726                                        third layer  42.0  \n",
       "19  0.827700  doubled the first layer and added a second one...  42.0  \n",
       "20  0.832003                                         base model  42.0  \n",
       "21  0.824098  took out the fully connected layers before the...  42.0  \n",
       "22  0.830427               added back one fully connected layer  42.0  \n",
       "23  0.830381  doubled pool size, except for last, doubled nu...  42.0  \n",
       "24  0.832270                       base model with same padding  42.0  \n",
       "25  0.841306            doubled last layer in all blocks. lr/10  42.0  \n",
       "26  0.842578  doubled last layer in all blocks doubled size ...  42.0  \n",
       "27  0.841536               added dropout layers to dense layers  42.0  \n",
       "28  0.834111    everything had 3 layers now and relu activation  42.0  \n",
       "29  0.832301                                     dropout layers  42.0  \n",
       "30  0.815836                                     dropout layers  42.0  \n",
       "31  0.813889                                     dropout layers  42.0  \n",
       "32  0.812370  new dataset using best model (base model with ...  42.0  \n",
       "33  0.827187                                             10x lr  42.0  \n",
       "34  0.826250                                             1/4 lr  42.0  \n",
       "35  0.848162                                             1/4 lr  42.0  \n",
       "36  0.854332                                             1/4 lr  42.0  \n",
       "37  0.876402                                             1/4 lr  42.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if not KAGGLE:\n",
    "pd.read_csv(\"../models/results.csv\", index_col=[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PARAMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-15T15:02:31.410867Z",
     "iopub.status.busy": "2021-09-15T15:02:31.410426Z",
     "iopub.status.idle": "2021-09-15T15:02:37.49379Z",
     "shell.execute_reply": "2021-09-15T15:02:37.492936Z",
     "shell.execute_reply.started": "2021-09-15T15:02:31.410829Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: NVIDIA GeForce RTX 3090, compute capability 8.6\n",
      "Running on 1 replica\n"
     ]
    }
   ],
   "source": [
    "strategy, TPU_Detected, REPLICAS = auto_select_accelerator()\n",
    "INPUT_DIR = \"../input/g2net-gravitational-wave-detection\"\n",
    "MDLS_PATH = \".\" if KAGGLE else \"../models\"\n",
    "TRAIN_FILES_PATH = \"../input/filtered*_tfrec\"\n",
    "AUTO = tf.data.experimental.AUTOTUNE\n",
    "tfrec_folders = [\"filtered_tfrec\", \"filtered_whitened_tfrec\", \"filtered_whitened_inverted_tfrec\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-15T15:02:37.495148Z",
     "iopub.status.busy": "2021-09-15T15:02:37.494768Z",
     "iopub.status.idle": "2021-09-15T15:02:37.719147Z",
     "shell.execute_reply": "2021-09-15T15:02:37.718274Z",
     "shell.execute_reply.started": "2021-09-15T15:02:37.495118Z"
    }
   },
   "outputs": [],
   "source": [
    "if KAGGLE:\n",
    "    from kaggle_secrets import UserSecretsClient\n",
    "    user_secrets = UserSecretsClient()\n",
    "    user_credential = user_secrets.get_gcloud_credential()\n",
    "    user_secrets.set_tensorflow_credential(user_credential)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-15T15:02:37.721115Z",
     "iopub.status.busy": "2021-09-15T15:02:37.720819Z",
     "iopub.status.idle": "2021-09-15T15:02:37.728148Z",
     "shell.execute_reply": "2021-09-15T15:02:37.727068Z",
     "shell.execute_reply.started": "2021-09-15T15:02:37.721075Z"
    }
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(f\"{MDLS_PATH}/results.csv\"):\n",
    "    VER = 1\n",
    "else:\n",
    "    results = pd.read_csv(f\"{MDLS_PATH}/results.csv\", index_col=[0])\n",
    "    VER = int(results.version.max())\n",
    "Params ={\n",
    "    \"lr\": 0.0001 * REPLICAS,\n",
    "    \"version\": VER,\n",
    "    \"train_mode\": \"full\", #test, full\n",
    "    \"batch_size\": 256 * REPLICAS,\n",
    "    \"epochs\":100,\n",
    "    \"seed\": 42,\n",
    "    \"changelog\": \"1/4 lr\",\n",
    "}\n",
    "seed_everything(Params[\"seed\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make Model directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-15T15:02:37.730162Z",
     "iopub.status.busy": "2021-09-15T15:02:37.729642Z",
     "iopub.status.idle": "2021-09-15T15:02:37.739448Z",
     "shell.execute_reply": "2021-09-15T15:02:37.73844Z",
     "shell.execute_reply.started": "2021-09-15T15:02:37.730121Z"
    }
   },
   "outputs": [],
   "source": [
    "VER = Params[\"version\"]\n",
    "MDL_PATH = f\"{MDLS_PATH}/models_v{VER:03}\"\n",
    "while os.path.exists(MDL_PATH):\n",
    "    VER += 1\n",
    "    MDL_PATH = f\"{MDLS_PATH}/models_v{VER:03}\"\n",
    "Params[\"version\"]=VER\n",
    "os.mkdir(MDL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-15T15:02:37.743841Z",
     "iopub.status.busy": "2021-09-15T15:02:37.743614Z",
     "iopub.status.idle": "2021-09-15T15:02:37.75515Z",
     "shell.execute_reply": "2021-09-15T15:02:37.754062Z",
     "shell.execute_reply.started": "2021-09-15T15:02:37.743817Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_dataset(files, shuffle=True, ordered=False, labeled = True, repeat=True):\n",
    "    dataset = tf.data.TFRecordDataset(files, num_parallel_reads=AUTO)\n",
    "\n",
    "    def _parse_function(example_proto):\n",
    "        if labeled:\n",
    "            keys_to_feature = {\n",
    "                \"TimeSeries\":tf.io.FixedLenFeature([4096,3],tf.float32),\n",
    "                \"Target\":tf.io.FixedLenFeature([], tf.int64, default_value=0)}\n",
    "        else:\n",
    "            keys_to_feature = {\n",
    "                \"TimeSeries\": tf.io.FixedLenFeature([4096,3],tf.float32)\n",
    "            }\n",
    "        parsed_features = tf.io.parse_single_example(example_proto, keys_to_feature)\n",
    "        return parsed_features[\"TimeSeries\"], parsed_features[\"Target\"] if labeled else parsed_features[\"TimeSeries\"]\n",
    "    \n",
    "    if not ordered:\n",
    "        ignore_order = tf.data.Options()\n",
    "        ignore_order.experimental_deterministic=False\n",
    "        dataset = dataset.with_options(ignore_order)\n",
    "    # parse the record into tensors.\n",
    "    dataset = dataset.map(_parse_function, num_parallel_calls=AUTO)\n",
    "    dataset = dataset.cache()\n",
    "\n",
    "    # shuffle the dataset\n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(buffer_size=10000)\n",
    "\n",
    "    # Repeat the input infinitely\n",
    "    if repeat:\n",
    "        dataset = dataset.repeat()\n",
    "\n",
    "\n",
    "    # Generate batches\n",
    "    dataset = dataset.batch(Params[\"batch_size\"])\n",
    "    dataset = dataset.prefetch(-1)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_val_files(folders):\n",
    "    train_files = []\n",
    "    test_files = []\n",
    "    for folder in folders:\n",
    "        if KAGGLE:\n",
    "            TRAIN_FILES_PATH = KaggleDatasets().get_gcs_path(folder)\n",
    "            tr_files = np.sort(tf.io.gfile.glob(f\"{TRAIN_FILES_PATH}/train_*.tfrec\"))\n",
    "        else:\n",
    "            all_files = np.sort(glob(f\"../input/{folder}/train_*.tfrec\"))        \n",
    "        train_files.extend(all_files[:-2])\n",
    "        test_files.extend(all_files[-2:])\n",
    "    return train_files, test_files\n",
    "\n",
    "train_files, val_files = get_train_val_files(tfrec_folders)\n",
    "train_ds = load_dataset(train_files)\n",
    "val_ds = load_dataset(val_files)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-15T15:02:37.771951Z",
     "iopub.status.busy": "2021-09-15T15:02:37.771726Z",
     "iopub.status.idle": "2021-09-15T15:02:39.668641Z",
     "shell.execute_reply": "2021-09-15T15:02:39.667667Z",
     "shell.execute_reply.started": "2021-09-15T15:02:37.771928Z"
    }
   },
   "source": [
    "if KAGGLE:\n",
    "    TRAIN_FILES_PATH = KaggleDatasets().get_gcs_path(\"filtered-tfrec\")\n",
    "    tr_files = tf.io.gfile.glob(f\"{TRAIN_FILES_PATH}/train_*.tfrec\")\n",
    "else:\n",
    "    tr_files = glob(f\"{TRAIN_FILES_PATH}/*train_*.tfrec\")\n",
    "if Params[\"train_mode\"] == \"test\":\n",
    "    train_files = tr_files[:3]\n",
    "    val_files = [tr_files[3]]\n",
    "\n",
    "elif Params[\"train_mode\"] == \"full\":\n",
    "    train_files = tr_files[:-2]\n",
    "    val_files = tr_files[-2:]\n",
    "    \n",
    "else:\n",
    "    raise AttributeError(\"Unknown Params['train_mode']\")\n",
    "\n",
    "train_ds = load_dataset(train_files)\n",
    "val_ds = load_dataset(val_files, shuffle=False, ordered=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-15T15:02:39.670012Z",
     "iopub.status.busy": "2021-09-15T15:02:39.669804Z",
     "iopub.status.idle": "2021-09-15T15:02:40.728147Z",
     "shell.execute_reply": "2021-09-15T15:02:40.727152Z",
     "shell.execute_reply.started": "2021-09-15T15:02:39.669988Z"
    }
   },
   "source": [
    "from tensorflow.keras import Sequential, layers\n",
    "with strategy.scope():\n",
    "    model = Sequential([\n",
    "        layers.Conv1D(filters=32, kernel_size=16, padding=\"causal\",input_shape=[4096,3]),\n",
    "        layers.MaxPool1D(pool_size=4),\n",
    "        layers.Activation(\"relu\"),\n",
    "        \n",
    "        layers.Conv1D(filters=64, kernel_size=8, padding=\"causal\"),\n",
    "        layers.Conv1D(filters=128, kernel_size=8, padding=\"causal\"),\n",
    "        layers.Conv1D(filters=128, kernel_size=8, padding=\"causal\"),\n",
    "        layers.MaxPool1D(pool_size=4),\n",
    "        layers.Dropout(0.4),\n",
    "        layers.Activation(\"relu\"),\n",
    "        \n",
    "        layers.Conv1D(filters=128, kernel_size=8, padding=\"causal\"),\n",
    "        layers.MaxPool1D(pool_size=4),\n",
    "        layers.Activation(\"relu\"),\n",
    "        \n",
    "        layers.Conv1D(filters=256, kernel_size=8, padding=\"causal\"),\n",
    "        layers.MaxPool1D(pool_size=4),\n",
    "        layers.Activation(\"relu\"),\n",
    "        \n",
    "        layers.Flatten(),\n",
    "        layers.Dense(128, activation=\"relu\"),\n",
    "        layers.Dense(64, activation=\"relu\"),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(1),\n",
    "        layers.Activation(\"sigmoid\", dtype=\"float32\")\n",
    "    ])\n",
    "    model.compile(\n",
    "        tf.keras.optimizers.Adam(learning_rate = Params[\"lr\"]),\n",
    "        loss=\"binary_crossentropy\",\n",
    "        metrics=[\"AUC\"]\n",
    "    )\n",
    "    model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-15T14:03:21.017763Z",
     "iopub.status.busy": "2021-09-15T14:03:21.017538Z",
     "iopub.status.idle": "2021-09-15T14:03:22.376581Z",
     "shell.execute_reply": "2021-09-15T14:03:22.375662Z",
     "shell.execute_reply.started": "2021-09-15T14:03:21.017737Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 4096, 32)          1568      \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 1024, 32)          0         \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 1024, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 1024, 64)          16448     \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 1024, 128)         65664     \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 1024, 128)         131200    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 256, 128)          0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 256, 128)          0         \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 256, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 256, 128)          131200    \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 256, 128)          131200    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 64, 128)           0         \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 64, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, 64, 256)           262400    \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 64, 256)           524544    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 16, 256)           0         \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 16, 256)           0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               524416    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 65        \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 1,796,961\n",
      "Trainable params: 1,796,961\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import Sequential, layers\n",
    "with strategy.scope():\n",
    "    model = Sequential([\n",
    "        layers.Conv1D(filters=32, kernel_size=16, padding=\"causal\",input_shape=[4096,3]),\n",
    "        layers.MaxPool1D(pool_size=4),\n",
    "        layers.Activation(\"relu\"),\n",
    "        \n",
    "        layers.Conv1D(filters=64, kernel_size=8, padding=\"causal\"),\n",
    "        layers.Conv1D(filters=128, kernel_size=8, padding=\"causal\"),\n",
    "        layers.Conv1D(filters=128, kernel_size=8, padding=\"causal\"),\n",
    "        layers.MaxPool1D(pool_size=4),\n",
    "        layers.Dropout(0.4),\n",
    "        layers.Activation(\"relu\"),\n",
    "        \n",
    "        layers.Conv1D(filters=128, kernel_size=8, padding=\"causal\"),\n",
    "        layers.Conv1D(filters=128, kernel_size=8, padding=\"causal\"),\n",
    "        layers.MaxPool1D(pool_size=4),\n",
    "        layers.Activation(\"relu\"),\n",
    "        \n",
    "        layers.Conv1D(filters=256, kernel_size=8, padding=\"causal\"),\n",
    "        layers.Conv1D(filters=256, kernel_size=8, padding=\"causal\"),\n",
    "        layers.MaxPool1D(pool_size=4),\n",
    "        layers.Activation(\"relu\"),\n",
    "        \n",
    "        layers.Flatten(),\n",
    "        layers.Dense(128, activation=\"relu\"),\n",
    "        layers.Dense(64, activation=\"relu\"),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(1),\n",
    "        layers.Activation(\"sigmoid\", dtype=\"float32\")\n",
    "    ])\n",
    "    model.compile(\n",
    "        tf.keras.optimizers.Adam(learning_rate = Params[\"lr\"]),\n",
    "        loss=\"binary_crossentropy\",\n",
    "        metrics=[\"AUC\"]\n",
    "    )\n",
    "    model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-15T15:02:40.72962Z",
     "iopub.status.busy": "2021-09-15T15:02:40.729411Z",
     "iopub.status.idle": "2021-09-15T15:02:40.734732Z",
     "shell.execute_reply": "2021-09-15T15:02:40.733878Z",
     "shell.execute_reply.started": "2021-09-15T15:02:40.729595Z"
    }
   },
   "outputs": [],
   "source": [
    "steps_per_epoch = 560000 // 16 * len(train_files) // Params[\"batch_size\"]\n",
    "validation_steps = 560000 // 16 * len(val_files) // Params[\"batch_size\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-15T15:02:40.736234Z",
     "iopub.status.busy": "2021-09-15T15:02:40.736024Z",
     "iopub.status.idle": "2021-09-15T15:02:40.747399Z",
     "shell.execute_reply": "2021-09-15T15:02:40.746577Z",
     "shell.execute_reply.started": "2021-09-15T15:02:40.73621Z"
    }
   },
   "outputs": [],
   "source": [
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor=\"val_loss\", factor=0.2,\n",
    "    patience=3, min_lr = 0.000001,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    mode=\"min\",\n",
    "    patience=5\n",
    ")\n",
    "\n",
    "model_checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    f\"{MDL_PATH}/model_{Params['version']:03}.h5\"\n",
    ")\n",
    "\n",
    "callbacks=[reduce_lr, early_stop, model_checkpoint]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model = tf.keras.models.load_model(\"../models/models_v040/model_040.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-09-15T15:02:40.750226Z",
     "iopub.status.busy": "2021-09-15T15:02:40.749704Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "5742/5742 [==============================] - 435s 74ms/step - loss: 0.5119 - auc: 0.7969 - val_loss: 0.4740 - val_auc: 0.8240\n",
      "Epoch 2/100\n",
      "2079/5742 [=========>....................] - ETA: 2:03 - loss: 0.4908 - auc: 0.810"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_ds, validation_data = val_ds, epochs = Params[\"epochs\"], shuffle=True,\n",
    "                    steps_per_epoch = steps_per_epoch, validation_steps=validation_steps,\n",
    "                    verbose=1, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "historyFrame = pd.DataFrame(history.history)\n",
    "historyFrame[[\"auc\", \"val_auc\"]].plot()\n",
    "historyFrame[[\"loss\", \"val_loss\"]].plot()\n",
    "historyFrame.to_csv(f\"{MDL_PATH}/history_mdl{Params['version']:03}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historyFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_epoch = historyFrame.val_auc.argmax()\n",
    "best_loss = historyFrame.iloc[best_epoch].loss\n",
    "best_auc = historyFrame.iloc[best_epoch].val_auc\n",
    "print(\"best epoch:\", best_epoch,\n",
    "      \"| best loss:\", best_loss,\n",
    "      \"| best auc:\", best_auc\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = Params.copy()\n",
    "result[\"bavg_epoch\"] = int(best_epoch)\n",
    "result[\"bavg_loss\"] = float(best_loss)\n",
    "result[\"bavg_auc\"] = float(best_auc)\n",
    "with open(f\"{MDL_PATH}/params.json\", \"w\") as file:\n",
    "    json.dump(result, file)\n",
    "\n",
    "if not os.path.exists(f\"{MDLS_PATH}/results.csv\"):\n",
    "    df_save = pd.DataFrame(result, index=[0])\n",
    "    df_save.to_csv(f\"{MDLS_PATH}/results.csv\")\n",
    "else:\n",
    "    df_old = pd.read_csv(f\"{MDLS_PATH}/results.csv\", index_col=0)\n",
    "    df_save = pd.DataFrame(result, index = [df_old.index.max() + 1])\n",
    "    df_save = df_old.append(df_save, ignore_index=True)\n",
    "    df_save.to_csv(f\"{MDLS_PATH}/results.csv\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(f\"{MDLS_PATH}/results.csv\",index_col=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if KAGGLE:\n",
    "    te_files = tf.io.gfile.glob(f\"{TRAIN_FILES_PATH}/test_*.tfrec\")\n",
    "else:\n",
    "    te_files = glob(f\"{TRAIN_FILES_PATH}/test_*.tfrec\")\n",
    "    te_files = glob(f\"../input/filtered_tfrec/test_*.tfrec\")\n",
    "test_set = load_dataset(te_files, shuffle=False, ordered=True, labeled=False, repeat=False)\n",
    "test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "with strategy.scope():\n",
    "    model = tf.keras.models.load_model(f\"{MDL_PATH}/model_{Params['version']:03}.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv(\"../input/g2net-gravitational-wave-detection/sample_submission.csv\")\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "sub.target = prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv(f\"{MDL_PATH}/submission.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "tr_files = glob(f\"{TRAIN_FILES_PATH}/train_*\")\n",
    "train_set = load_dataset(tr_files, shuffle=False, ordered=True, labeled=False, repeat=False)\n",
    "pred_tr = model.predict(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(f\"{INPUT_DIR}/training_labels.csv\")\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(train_df.target, pred_tr)\n",
    "test_y = np.load(f\"{INPUT_DIR}/train_x.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.predict(test_y, batch_size = 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
