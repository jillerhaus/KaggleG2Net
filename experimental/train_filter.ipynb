{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "acbe8695",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General\n",
    "import os\n",
    "import numpy as np\n",
    "import sys\n",
    "from glob import glob\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "#ML\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import mixed_precision, layers\n",
    "mixed_precision.set_global_policy(\"mixed_float16\")\n",
    "AUTO = tf.data.experimental.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1d7745d",
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_devices = tf.config.list_physical_devices(\"GPU\")\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7107045",
   "metadata": {},
   "outputs": [],
   "source": [
    "Params = {\n",
    "    \"batch_size\": 128\n",
    "}"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8f5ed7ad",
   "metadata": {},
   "source": [
    "def make_windows(batch, y):\n",
    "    batch=np.array(batch)\n",
    "#     print(batch.shape)\n",
    "    batch = np.transpose(batch,[1,2,0])\n",
    "#     print(batch.shape)\n",
    "    batch = tf.keras.preprocessing.timeseries_dataset_from_array(batch,\n",
    "                                                              targets=None,\n",
    "                                                              sequence_length=4,\n",
    "                                                              batch_size=4096\n",
    "                                                            )\n",
    "    print(type(batch))\n",
    "    batch = tf.transpose(batch,[3,0,1,2])\n",
    "    paddings = tf.constant([\n",
    "        [0,0],\n",
    "        [0,4096-batch.shape[1]],\n",
    "        [0,0],\n",
    "        [0,0]\n",
    "    ])\n",
    "    batch = tf.pad(batch, paddings=paddings)\n",
    "#     batch = np.array(batch)\n",
    "#     print(batch.shape)\n",
    "    return batch,y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cdaaa931",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_cut(x,y):\n",
    "    tensor = x\n",
    "    tensor_y = y\n",
    "    maxVal=128\n",
    "    dt = tf.random.uniform(shape=[],minval=2, maxval=maxVal, dtype=tf.int32)\n",
    "    t0 = tf.random.uniform(shape=[],minval=1, maxval=dt, dtype=tf.int32)\n",
    "    t1 = tf.random.uniform(shape=[],minval=0, maxval=t0, dtype=tf.int32)\n",
    "    paddings =  [\n",
    "        [0,0],\n",
    "        [t1,dt-t1],\n",
    "        [0,0]\n",
    "    ]\n",
    "    tensor = tf.pad(tensor[:,t0:t0+(4096-dt)], paddings=paddings)\n",
    "    tensor_y = tf.pad(tensor_y[:,t0:t0+4096-dt], paddings=paddings)\n",
    "    tensor = tf.reshape(tensor,[Params[\"batch_size\"], 4096, 3])\n",
    "    tensor_y = tf.reshape(tensor_y,[Params[\"batch_size\"], 4096, 3])\n",
    "        \n",
    "    \n",
    "    tensor = tf.cast(tensor, tf.float32)\n",
    "    tensor_y = tf.cast(tensor_y, tf.float32)\n",
    "    \n",
    "    return tensor, tensor_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21882e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(files, window=True):\n",
    "    dataset = tf.data.TFRecordDataset(files, num_parallel_reads = AUTO)\n",
    "    \n",
    "    def _parse_function(example_proto):\n",
    "        keys_to_feature = {}\n",
    "        keys_to_feature[\"TimeSeries\"] = tf.io.FixedLenFeature([4096,3], tf.float32)\n",
    "        keys_to_feature[\"GroundTruths\"] = tf.io.FixedLenFeature([4096,3], tf.float32)\n",
    "        \n",
    "        parsed_features = tf.io.parse_single_example(example_proto, keys_to_feature)\n",
    "        return parsed_features[\"TimeSeries\"], parsed_features[\"GroundTruths\"]\n",
    "    \n",
    "    dataset = dataset.map(_parse_function, num_parallel_calls=AUTO)\n",
    "    dataset = dataset.repeat()\n",
    "    dataset = dataset.shuffle(buffer_size=10000, reshuffle_each_iteration=True)\n",
    "    dataset = dataset.batch(Params[\"batch_size\"])\n",
    "    dataset = dataset.map(random_cut, num_parallel_calls=AUTO)\n",
    "#     dataset = dataset.cache()\n",
    "    dataset = dataset.prefetch(AUTO)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e38d9a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset_files(distances):\n",
    "    train_files = []\n",
    "    val_files = []\n",
    "    for distance in distances:\n",
    "        data_files = glob(f\"../input/synthetic-tfrec/train_{distance}*.tfrec\")\n",
    "        train_files.extend(data_files[:-1])\n",
    "        val_files.extend(data_files[-1:])\n",
    "    return train_files, val_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a434860",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../input/synthetic-tfrec\\\\train_100_12500_00.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_100_12500_01.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_100_12500_02.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_100_12500_03.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_100_12500_04.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_100_12500_05.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_100_12500_06.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_150_12500_00.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_150_12500_01.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_150_12500_02.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_150_12500_03.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_150_12500_04.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_150_12500_05.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_150_12500_06.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_200_12500_00.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_200_12500_01.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_200_12500_02.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_200_12500_03.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_200_12500_04.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_200_12500_05.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_200_12500_06.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_200_12500_07.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_200_2_12500_00.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_200_2_12500_01.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_200_2_12500_02.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_200_2_12500_03.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_200_2_12500_04.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_200_2_12500_05.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_200_2_12500_06.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_200_2_12500_07.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_200_3_12500_00.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_200_3_12500_01.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_200_3_12500_02.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_200_3_12500_03.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_200_3_12500_04.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_200_3_12500_05.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_200_3_12500_06.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_250_12500_00.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_250_12500_01.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_250_12500_02.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_250_12500_03.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_250_12500_04.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_250_12500_05.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_250_12500_06.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_250_12500_07.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_250_2_12500_00.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_250_2_12500_01.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_250_2_12500_02.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_250_2_12500_03.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_250_2_12500_04.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_250_2_12500_05.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_250_2_12500_06.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_300_12500_00.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_300_12500_01.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_300_12500_02.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_300_12500_03.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_300_12500_04.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_300_12500_05.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_300_12500_06.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_300_12500_07.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_300_2_12500_00.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_300_2_12500_01.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_300_2_12500_02.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_300_2_12500_03.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_300_2_12500_04.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_300_2_12500_05.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_300_2_12500_06.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_300_2_12500_07.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_300_3_12500_00.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_300_3_12500_01.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_300_3_12500_02.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_300_3_12500_03.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_300_3_12500_04.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_300_3_12500_05.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_300_3_12500_06.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_350_12500_00.tfrec']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_files,val_files = get_dataset_files([100,150,200,250,300,350])\n",
    "train_ds = load_dataset(train_files)\n",
    "val_ds = load_dataset(val_files)\n",
    "train_files"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3c98132c",
   "metadata": {},
   "source": [
    "for i in tf.keras.preprocessing.timeseries_dataset_from_array(tf.transpose(tensor[0],[1,2,0]),\n",
    "                                                              targets=None,\n",
    "                                                              length=4,\n",
    "                                                              batch_size=4096\n",
    "                                                             ):\n",
    "    result = tf.transpose(i, [3,0,1,2])\n",
    "    print(result.shape)\n",
    "    \n",
    "    break\n",
    "result = tf.pad(result, paddings=tf.constant([\n",
    "    [0,0],\n",
    "    [0,4096-result.shape[1]],\n",
    "    [0,0],\n",
    "    [0,0]\n",
    "]))\n",
    "print(result.shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "raw",
   "id": "7f0330ec",
   "metadata": {},
   "source": [
    "def make_windows(batch):\n",
    "    batch = tf.transpose(batch,[1,2,0])\n",
    "    batch = tf.keras.preprocessing.sequence.TimeseriesGenerator(batch,\n",
    "                                                              targets=None,\n",
    "                                                              length=4,\n",
    "                                                              batch_size=4096\n",
    "                                                            )\n",
    "    batch = tf.transpose(batch,[3,0,1,2])\n",
    "    paddings = tf.constant([\n",
    "        [0,0],\n",
    "        [0,4096-batch.shape[1]],\n",
    "        [0,0],\n",
    "        [0,0]\n",
    "    ])\n",
    "    batch = tf.pad(batch, paddings=paddings)\n",
    "    return batch\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9cf72642",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 1, 4), dtype=float32, numpy=\n",
       "array([[[1., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 1., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 1., 0.]],\n",
       "\n",
       "       [[0., 0., 0., 1.]]], dtype=float32)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def ownInitializer(shape, dtype=None):\n",
    "    return tf.constant([\n",
    "        [[1,0,0,0]],\n",
    "        [[0,1,0,0]],\n",
    "        [[0,0,1,0]],\n",
    "        [[0,0,0,1]]\n",
    "    ],dtype=dtype)\n",
    "\n",
    "ownInitializer(2,tf.float32)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fcf8ddd4",
   "metadata": {},
   "source": [
    "def ownInitializer(shape, dtype=None):\n",
    "    return tf.constant([\n",
    "        [[1,0,0,0],[1,0,0,0],[1,0,0,0]],\n",
    "        [[0,1,0,0],[0,1,0,0],[0,1,0,0]],\n",
    "        [[0,0,1,0],[0,0,1,0],[0,0,1,0]],\n",
    "        [[0,0,0,1],[0,0,0,1],[0,0,0,1]]\n",
    "    ],dtype=dtype)\n",
    "\n",
    "ownInitializer(2,tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "55a3c709",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\apist\\AppData\\Local\\Temp/ipykernel_29160/2700824021.py:16: The name tf.keras.layers.CuDNNLSTM is deprecated. Please use tf.compat.v1.keras.layers.CuDNNLSTM instead.\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 4096, 12)          156       \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 4096, 12, 1)       0         \n",
      "_________________________________________________________________\n",
      "time_distributed (TimeDistri (None, 4096, 12, 32)      192       \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 4096, 12, 32)      5152      \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, 4096, 6, 32)       0         \n",
      "_________________________________________________________________\n",
      "time_distributed_3 (TimeDist (None, 4096, 6, 16)       2576      \n",
      "_________________________________________________________________\n",
      "time_distributed_4 (TimeDist (None, 4096, 96)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 4096, 256)         231424    \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 4096, 256)         395264    \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 4096, 256)         395264    \n",
      "_________________________________________________________________\n",
      "time_distributed_5 (TimeDist (None, 4096, 3)           771       \n",
      "=================================================================\n",
      "Total params: 1,030,799\n",
      "Trainable params: 1,030,799\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.Input(shape = [4096,3]),\n",
    "#         layers.Conv1D(kernel_size=12, filters=4,\n",
    "#                        kernel_initializer=ownInitializer, input_shape=[4096,3], trainable=True, padding=\"same\"),\n",
    "    layers.Conv1D(kernel_size=4, filters=12, padding=\"same\"),\n",
    "#     layers.ZeroPadding1D(padding=[0,3]),\n",
    "    layers.Reshape([4096,12,1]),\n",
    "    layers.TimeDistributed(layers.Conv1D(kernel_size=3, filters=32, activation=\"tanh\", padding=\"same\")),\n",
    "#     layers.TimeDistributed(layers.Conv1D(kernel_size=5, filters=32, activation=\"tanh\", padding=\"same\")),\n",
    "    \n",
    "    layers.TimeDistributed(layers.MaxPool1D()),\n",
    "    layers.TimeDistributed(layers.Conv1D(kernel_size=3, filters=16, activation=\"tanh\", padding=\"same\")),\n",
    "    layers.TimeDistributed(layers.Flatten()),\n",
    "    \n",
    "#     layers.Reshape([4093,32]),\n",
    "    layers.Bidirectional(tf.compat.v1.keras.layers.CuDNNLSTM(128, return_sequences=True)),\n",
    "    layers.Bidirectional(tf.compat.v1.keras.layers.CuDNNLSTM(128, return_sequences=True)),\n",
    "    layers.Bidirectional(tf.compat.v1.keras.layers.CuDNNLSTM(128, return_sequences=True)),\n",
    "    \n",
    "#     layers.Bidirectional(layers.LSTM(100, return_sequences=True)),\n",
    "#     layers.Bidirectional(layers.LSTM(100, return_sequences=True)),\n",
    "#     layers.Bidirectional(layers.LSTM(100, return_sequences=True)),\n",
    "    \n",
    "    \n",
    "#     layers.Bidirectional(layers.LSTM(400)),\n",
    "    \n",
    "    \n",
    "    layers.TimeDistributed(layers.Dense(3, dtype=tf.float32)),\n",
    "])\n",
    "opt = tf.keras.optimizers.Adam(learning_rate = 0.0001)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=opt,\n",
    "    metrics=[\"mean_squared_error\", \"cosine_similarity\"],\n",
    "    loss=\"mean_squared_error\"\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3acd10c5",
   "metadata": {},
   "source": [
    "for x in train_ds:\n",
    "    tensor = x\n",
    "    break\n",
    "tensor[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "38c9651d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model=tf.keras.models.load_model(\"model2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cab5dadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_steps = len(train_files) * 12500 // Params[\"batch_size\"]\n",
    "val_steps = len(val_files) * 12500 // Params[\"batch_size\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8068783c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import *\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor=\"val_loss\", factor=0.2,\n",
    "    patience=5, min_lr = 0.000001,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    mode=\"min\",\n",
    "    patience=10\n",
    ")\n",
    "\n",
    "model_checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "#     f\"{MDL_PATH}/model_{Params['version']:03}.h5\",\n",
    "    \"./model4.h5\",\n",
    "    monitor=\"val_loss\",\n",
    "    verbose=0,\n",
    "    save_best_only=True,\n",
    "    save_weight_only=False,\n",
    "    mode=\"auto\",\n",
    "    save_freq=\"epoch\"\n",
    ")\n",
    "\n",
    "\n",
    "callbacks=[reduce_lr, early_stop, model_checkpoint]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "94024108",
   "metadata": {},
   "source": [
    "model.optimizer.learning_rate = model.optimizer.learning_rate / 10"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3f4b924e",
   "metadata": {},
   "source": [
    "model = tf.keras.models.load_model(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9f6def",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85730b5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "4783/7421 [==================>...........] - ETA: 36:26 - loss: 0.0108 - mean_squared_error: 0.0108 - cosine_similarity: 0.0423"
     ]
    }
   ],
   "source": [
    "model.fit(train_ds,validation_data=val_ds, validation_steps=val_steps, steps_per_epoch=train_steps,\n",
    "          epochs=60, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff7716d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "predictions = model.predict(train_ds, steps=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901ae492",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538ff0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "for i in range(1000,1050):\n",
    "    \n",
    "    plt.plot(predictions[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633ddb2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in train_ds:\n",
    "    plt.plot(i[1][7])\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a926852",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model2.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
