{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07e80813",
   "metadata": {},
   "source": [
    "# Train Filter\n",
    "\n",
    "This notebook is designed to train the filter for the model. The filter is currently designed to take sample made up of a time series with three channels (one from each of the LIGO/Virgo detectors). Each of these samples contains 2s of either just noise or a gravitational wave overlayed with noise. The data is sampled at 2048 Hz.The filter will then try to reconstruct the gravitational wave. Or in the case of just noise, the ground truth is just a constant line at 0."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4acf71e",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f81b01",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80992384",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General\n",
    "import os\n",
    "import numpy as np\n",
    "import sys\n",
    "from glob import glob\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "#ML\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import mixed_precision, layers\n",
    "mixed_precision.set_global_policy(\"mixed_float16\")\n",
    "AUTO = tf.data.experimental.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1d7745d",
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_devices = tf.config.list_physical_devices(\"GPU\")\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a180090a",
   "metadata": {},
   "source": [
    "### Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7107045",
   "metadata": {},
   "outputs": [],
   "source": [
    "Params = {\n",
    "    \"batch_size\": 128\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c7bfa50",
   "metadata": {},
   "source": [
    "## Convenience Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30563088",
   "metadata": {},
   "source": [
    "### load_dataset()\n",
    "\n",
    "This function will load the dataset from different `tfrec` files. The datasets include a \"ground truth\", which is a time series containing either the un-whitened gravitational wave or a vector of 0. The ground truth tensors were not whitened, because the loss function used was the root mean squared error (RMSE), which lead to ill-posed models in cases where the signal was whitened, because in those cases there was only one time point with a high amplitude, compared to all others, that were very close to 0. RMSE was chosen, because in this case it was not necessary to reproduce the wavelet as exactly as possible, but to make a clear distinction between samples only containing noise and those with a signal. In the end the reproduced wavelets were very close to the ground truths regardless, at leas on the synthetically created datasets. These however turned out to be too far removed from the Kaggle dataset. The reasons for this are discussed in `train.ipynb`.\n",
    "\n",
    "#### Dataset Creation\n",
    "In order to create the datasets, I have altered the data creation code discussed in [this paper](https://arxiv.org/pdf/1904.08693.pdf) to allow for the use of Virgo data in the creation of synthetic datasets, as well as added some little convenience changes. The altered version should be available on my github shortly.\n",
    "\n",
    "The data creation process goes as follows:\n",
    "\n",
    "1. Real detector noise is downloaded. The choice to use real detector noise was made, because in numerous papers discussing machine learning applied to gravitational-wave signal detection, the result has always been, that deep learning networks perform much better on the colored Gaussian noise resulting from synthetic noise creation than on actual detector noise, even when transient \"glitches\" are injected into the noise.\n",
    "\n",
    "2. Half of the samples are then injected with gravitational wave signals from black hole mergers chosen at random from all possible parameter sets (weight of the black holes, spin, etc.). The injections were limited to only black hole mergers as their duration will sensibly fit into the 2s window of data present in the Kaggle dataset. The assumption that only black hole mergers are used in the Kaggle dataset may be wrong. The simulated signals are injected and their signal to noise ratios(SNRs) are calculated using matched filtering. They are then scaled to produce SNRs in the chosen window, which was 3-20 in the synthetic datasets. This, however turned out not to work as expected, because in the actual testing datasets where the simulated masses were further away from the detectors were significantly easier for models trained on the Kaggle dataset to make predictions on than those with a closer distance, even though the reported SNR was the same in both cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21882e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(files):\n",
    "    dataset = tf.data.TFRecordDataset(files, num_parallel_reads = AUTO)\n",
    "    \n",
    "    def _parse_function(example_proto):\n",
    "        keys_to_feature = {}\n",
    "        keys_to_feature[\"TimeSeries\"] = tf.io.FixedLenFeature([4096,3], tf.float32)\n",
    "        keys_to_feature[\"GroundTruths\"] = tf.io.FixedLenFeature([4096,3], tf.float32)\n",
    "        \n",
    "        parsed_features = tf.io.parse_single_example(example_proto, keys_to_feature)\n",
    "        return parsed_features[\"TimeSeries\"], parsed_features[\"GroundTruths\"]\n",
    "    \n",
    "    dataset = dataset.map(_parse_function, num_parallel_calls=AUTO)\n",
    "    dataset = dataset.repeat()\n",
    "    dataset = dataset.shuffle(buffer_size=10000, reshuffle_each_iteration=True)\n",
    "    dataset = dataset.batch(Params[\"batch_size\"])\n",
    "    dataset = dataset.map(random_cut, num_parallel_calls=AUTO)\n",
    "#     dataset = dataset.cache()\n",
    "    dataset = dataset.prefetch(AUTO)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "167bac1a",
   "metadata": {},
   "source": [
    "### get_dataset_files()\n",
    "\n",
    "This function divides the files into a training and validation dataset. The function can be given distances to choose from, because in testing it was shown, that even though the signal to noise ratio should be the same at all distances, the datasets with a higher distance between the detector and the event were much harder(distance in the filename is in Mpc). In the end the filter is meant to be trained using curriculum learning, where the dataset is made increasingly more difficult as training progresses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e38d9a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset_files(distances):\n",
    "    train_files = []\n",
    "    val_files = []\n",
    "    for distance in distances:\n",
    "        data_files = glob(f\"../input/synthetic-tfrec/train_{distance}*.tfrec\")\n",
    "        train_files.extend(data_files[:-1])\n",
    "        val_files.extend(data_files[-1:])\n",
    "    return train_files, val_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a434860",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../input/synthetic-tfrec\\\\train_100_12500_00.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_100_12500_01.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_100_12500_02.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_100_12500_03.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_100_12500_04.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_100_12500_05.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_100_12500_06.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_150_12500_00.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_150_12500_01.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_150_12500_02.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_150_12500_03.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_150_12500_04.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_150_12500_05.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_150_12500_06.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_200_12500_00.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_200_12500_01.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_200_12500_02.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_200_12500_03.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_200_12500_04.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_200_12500_05.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_200_12500_06.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_200_12500_07.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_200_2_12500_00.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_200_2_12500_01.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_200_2_12500_02.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_200_2_12500_03.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_200_2_12500_04.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_200_2_12500_05.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_200_2_12500_06.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_200_2_12500_07.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_200_3_12500_00.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_200_3_12500_01.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_200_3_12500_02.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_200_3_12500_03.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_200_3_12500_04.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_200_3_12500_05.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_200_3_12500_06.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_250_12500_00.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_250_12500_01.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_250_12500_02.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_250_12500_03.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_250_12500_04.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_250_12500_05.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_250_12500_06.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_250_12500_07.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_250_2_12500_00.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_250_2_12500_01.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_250_2_12500_02.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_250_2_12500_03.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_250_2_12500_04.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_250_2_12500_05.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_250_2_12500_06.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_300_12500_00.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_300_12500_01.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_300_12500_02.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_300_12500_03.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_300_12500_04.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_300_12500_05.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_300_12500_06.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_300_12500_07.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_300_2_12500_00.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_300_2_12500_01.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_300_2_12500_02.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_300_2_12500_03.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_300_2_12500_04.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_300_2_12500_05.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_300_2_12500_06.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_300_2_12500_07.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_300_3_12500_00.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_300_3_12500_01.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_300_3_12500_02.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_300_3_12500_03.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_300_3_12500_04.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_300_3_12500_05.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_300_3_12500_06.tfrec',\n",
       " '../input/synthetic-tfrec\\\\train_350_12500_00.tfrec']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_files,val_files = get_dataset_files([100,150,200,250,300,350])\n",
    "train_ds = load_dataset(train_files)\n",
    "val_ds = load_dataset(val_files)\n",
    "train_files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559dd08a",
   "metadata": {},
   "source": [
    "## Train\n",
    "### Model\n",
    "\n",
    "The first and current architecture used for the filter is a 3-channel version of the architecture proposed in [this paper](https://arxiv.org/abs/2105.03073). It is a encoder, decoder model, where the encoding is done using a simple 1D CNN and the decoding is done using a series of bidirectional LSTM layers. Unfortunately, so far I have not yet had the chance to experiment much with the architecture, because my initial datasets have proven insufficient for training (too easy, pre-processing is different to that of Kaggle dataset). I am currently making better datasets to be able to experiment more with training the filter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08f3503",
   "metadata": {},
   "source": [
    "This custom initializer is meant as an initializer for a 1D convolutional layer to create a windowing effect, i.e. [x1,x2,x3,x4,x5,x5] => [[x1,x2,x3,x4],[x2,x3,x4,x5], ...]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9cf72642",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 1, 4), dtype=float32, numpy=\n",
       "array([[[1., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 1., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 1., 0.]],\n",
       "\n",
       "       [[0., 0., 0., 1.]]], dtype=float32)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def ownInitializer(shape, dtype=None):\n",
    "    return tf.constant([\n",
    "        [[1,0,0,0]],\n",
    "        [[0,1,0,0]],\n",
    "        [[0,0,1,0]],\n",
    "        [[0,0,0,1]]\n",
    "    ],dtype=dtype)\n",
    "\n",
    "ownInitializer(2,tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb6eb57e",
   "metadata": {},
   "source": [
    "Same principle but with 3 channels,which are added together. due to the loss of information this would produce, I decided to use a trainable and randomly initialized first layer. This was also done in large part due to time-constraints and will be re-visited."
   ]
  },
  {
   "cell_type": "raw",
   "id": "fcf8ddd4",
   "metadata": {},
   "source": [
    "def ownInitializer(shape, dtype=None):\n",
    "    return tf.constant([\n",
    "        [[1,0,0,0],[1,0,0,0],[1,0,0,0]],\n",
    "        [[0,1,0,0],[0,1,0,0],[0,1,0,0]],\n",
    "        [[0,0,1,0],[0,0,1,0],[0,0,1,0]],\n",
    "        [[0,0,0,1],[0,0,0,1],[0,0,0,1]]\n",
    "    ],dtype=dtype)\n",
    "\n",
    "ownInitializer(2,tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "55a3c709",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\apist\\AppData\\Local\\Temp/ipykernel_29160/2700824021.py:16: The name tf.keras.layers.CuDNNLSTM is deprecated. Please use tf.compat.v1.keras.layers.CuDNNLSTM instead.\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 4096, 12)          156       \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 4096, 12, 1)       0         \n",
      "_________________________________________________________________\n",
      "time_distributed (TimeDistri (None, 4096, 12, 32)      192       \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 4096, 12, 32)      5152      \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, 4096, 6, 32)       0         \n",
      "_________________________________________________________________\n",
      "time_distributed_3 (TimeDist (None, 4096, 6, 16)       2576      \n",
      "_________________________________________________________________\n",
      "time_distributed_4 (TimeDist (None, 4096, 96)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 4096, 256)         231424    \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 4096, 256)         395264    \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 4096, 256)         395264    \n",
      "_________________________________________________________________\n",
      "time_distributed_5 (TimeDist (None, 4096, 3)           771       \n",
      "=================================================================\n",
      "Total params: 1,030,799\n",
      "Trainable params: 1,030,799\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.Input(shape = [4096,3]),\n",
    "#         layers.Conv1D(kernel_size=12, filters=4,\n",
    "#                        kernel_initializer=ownInitializer, input_shape=[4096,3], trainable=True, padding=\"same\"),\n",
    "    layers.Conv1D(kernel_size=4, filters=12, padding=\"same\"),\n",
    "#     layers.ZeroPadding1D(padding=[0,3]),\n",
    "    layers.Reshape([4096,12,1]),\n",
    "    layers.TimeDistributed(layers.Conv1D(kernel_size=3, filters=32, activation=\"tanh\", padding=\"same\")),\n",
    "#     layers.TimeDistributed(layers.Conv1D(kernel_size=5, filters=32, activation=\"tanh\", padding=\"same\")),\n",
    "    \n",
    "    layers.TimeDistributed(layers.MaxPool1D()),\n",
    "    layers.TimeDistributed(layers.Conv1D(kernel_size=3, filters=16, activation=\"tanh\", padding=\"same\")),\n",
    "    layers.TimeDistributed(layers.Flatten()),\n",
    "    \n",
    "#     layers.Reshape([4093,32]),\n",
    "    layers.Bidirectional(tf.compat.v1.keras.layers.CuDNNLSTM(128, return_sequences=True)),\n",
    "    layers.Bidirectional(tf.compat.v1.keras.layers.CuDNNLSTM(128, return_sequences=True)),\n",
    "    layers.Bidirectional(tf.compat.v1.keras.layers.CuDNNLSTM(128, return_sequences=True)),\n",
    "    \n",
    "#     layers.Bidirectional(layers.LSTM(100, return_sequences=True)),\n",
    "#     layers.Bidirectional(layers.LSTM(100, return_sequences=True)),\n",
    "#     layers.Bidirectional(layers.LSTM(100, return_sequences=True)),\n",
    "    \n",
    "    \n",
    "#     layers.Bidirectional(layers.LSTM(400)),\n",
    "    \n",
    "    \n",
    "    layers.TimeDistributed(layers.Dense(3, dtype=tf.float32)),\n",
    "])\n",
    "opt = tf.keras.optimizers.Adam(learning_rate = 0.0001)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=opt,\n",
    "    metrics=[\"mean_squared_error\", \"cosine_similarity\"],\n",
    "    loss=\"mean_squared_error\"\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cab5dadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_steps = len(train_files) * 12500 // Params[\"batch_size\"]\n",
    "val_steps = len(val_files) * 12500 // Params[\"batch_size\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8068783c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import *\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor=\"val_loss\", factor=0.2,\n",
    "    patience=5, min_lr = 0.000001,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    mode=\"min\",\n",
    "    patience=10\n",
    ")\n",
    "\n",
    "model_checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "#     f\"{MDL_PATH}/model_{Params['version']:03}.h5\",\n",
    "    \"./model4.h5\",\n",
    "    monitor=\"val_loss\",\n",
    "    verbose=0,\n",
    "    save_best_only=True,\n",
    "    save_weight_only=False,\n",
    "    mode=\"auto\",\n",
    "    save_freq=\"epoch\"\n",
    ")\n",
    "\n",
    "\n",
    "callbacks=[reduce_lr, early_stop, model_checkpoint]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d62454",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85730b5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "4783/7421 [==================>...........] - ETA: 36:26 - loss: 0.0108 - mean_squared_error: 0.0108 - cosine_similarity: 0.0423"
     ]
    }
   ],
   "source": [
    "model.fit(train_ds,validation_data=val_ds, validation_steps=val_steps, steps_per_epoch=train_steps,\n",
    "          epochs=60, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac2c1a7a",
   "metadata": {},
   "source": [
    "### Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff7716d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "predictions = model.predict(train_ds, steps=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901ae492",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538ff0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "for i in range(1000,1050):\n",
    "    \n",
    "    plt.plot(predictions[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633ddb2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in train_ds:\n",
    "    plt.plot(i[1][7])\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a926852",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model2.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
