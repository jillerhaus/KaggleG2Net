{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b878e125",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5aba1f7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KAGGLE: False\n"
     ]
    }
   ],
   "source": [
    "import socket\n",
    "KAGGLE = True\n",
    "import re\n",
    "if ((re.compile(r\"computerfon\").search(socket.gethostname().lower())) != None):\n",
    "    KAGGLE = False\n",
    "print(f\"KAGGLE: {KAGGLE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd03268d",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96c8aba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if KAGGLE:\n",
    "    !pip install -q efficientnet\n",
    "    from kaggle_datasets import KaggleDatasets\n",
    "    \n",
    "# general\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import perf_counter\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "#ML\n",
    "#DL\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "import efficientnet.tfkeras as efn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "899bd9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not KAGGLE:\n",
    "    files_test_g = glob(\"../input/cqt-g2net-test*/*.tfrec\")\n",
    "    files_train_g = glob(\"../input/g2net-make-tfrecords*/*.tfrec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9df858",
   "metadata": {},
   "source": [
    "### PARAMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9da41c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def auto_select_accelerator():\n",
    "    TPU_DETECTED = False\n",
    "    try:\n",
    "        tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "        tf.config.experimental_connect_to_cluster(tpu)\n",
    "        tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "        strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "        print(f\"Running on TPU: {tpu.master()}\")\n",
    "        TPU_DETECTED = True\n",
    "    except ValueError:\n",
    "        strategy = tf.distribute.get_strategy()\n",
    "    REPLICAS = strategy.num_replicas_in_sync\n",
    "    print(f\"Running on {REPLICAS} replica{'s' if REPLICAS > 1 else ''}\")\n",
    "    return strategy, TPU_DETECTED, REPLICAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61b7d80f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glob(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1bc36add",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on 1 replica\n"
     ]
    }
   ],
   "source": [
    "class PARAMS:\n",
    "    COMPETITION_DATASET_PATH = \"../input/g2net-gravitational-wave detection\" if KAGGLE else \"../input/g2net-input\"\n",
    "    AUTO = tf.data.experimental.AUTOTUNE\n",
    "    STRATEGY, TPU_DETECTED, REPLICAS = auto_select_accelerator()\n",
    "    IMG_SIZES = 265\n",
    "    BATCH_SIZES = 64\n",
    "    FOLDS = range(4)\n",
    "    EFFNET = 7\n",
    "    PRETRAINED_MODEL_PATH = f\"../input/g2net-effnetb{EFFNET}\"\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb237557",
   "metadata": {},
   "source": [
    "## Middle Part (where the functions live)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b47ca8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_labeled_tfrecord(example):\n",
    "    tfrec_format = {\n",
    "        \"image\": tf.io.FixedLenFeature([], tf.string),\n",
    "        \"image_id\": tf.io.FixedLenFeature([], tf.string),\n",
    "        \"target\": tf.io.FixedLenFeature([], tf.int64)\n",
    "    }\n",
    "    example = tf.io.parse_single_example(example, tfrec_format)\n",
    "    return prepare_image(example[\"image\"]), tf.reshape(tf.cast(example[\"target\"], tf.float32), [1])\n",
    "\n",
    "def read_unlabeled_tfrecord(example, return_image_id):\n",
    "    tfrec_format = {\n",
    "        \"image\" : tf.io.FixedLenFeature([], tf.string),\n",
    "        \"image_id\" : tf.io.FixedLenFeature([], tf.string)\n",
    "    }\n",
    "    example = tf.io.parse_single_example(example, tfrec_format)\n",
    "    return prepare_image(example[\"image\"]), example[\"image_id\"] if return_image_id else 0\n",
    "\n",
    "def prepare_image(img, dim=PARAMS.IMG_SIZES):\n",
    "    img = tf.image.resize(tf.image.decode_png(img, channels=3), size=(dim, dim))\n",
    "    img = tf.cast(img, tf.float32) / 255.0\n",
    "    img = tf.reshape(img, [dim, dim, 3])\n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3bf63917",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(files,shuffle=False,repeat=False,\n",
    "               labeled=True,return_image_ids=True,batch_size=16,dim=PARAMS.IMG_SIZES):\n",
    "    ds = tf.data.TFRecordDataset(files, num_parallel_reads = PARAMS.AUTO)\n",
    "    ds.cache()\n",
    "    \n",
    "    if repeat:\n",
    "        ds = ds.repeat()\n",
    "        \n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(1024*2)\n",
    "        opt = tf.data.Options()\n",
    "        opt.exprimental_deterministic = False\n",
    "        df = ds.with_options(opt)\n",
    "        \n",
    "    if labeled:\n",
    "        ds = ds.map(read_labeled_tfrecord, num_parallel_calls=PARAMS.AUTO)\n",
    "    else:\n",
    "        ds = ds.map(lambda example: read_unlabeled_tfrecord(example, return_image_ids),\n",
    "                   num_parallel_calls=PARAMS.AUTO)\n",
    "    ds = ds.batch(batch_size * PARAMS.REPLICAS)\n",
    "    ds = ds.prefetch(PARAMS.AUTO)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d6c2bd3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "EFNS = [efn.EfficientNetB0, efn.EfficientNetB1, efn.EfficientNetB2, efn.EfficientNetB3,\n",
    "        efn.EfficientNetB4, efn.EfficientNetB5, efn.EfficientNetB6, efn.EfficientNetB7]\n",
    "\n",
    "def build_model(size, path):\n",
    "    inp = tf.keras.layers.Input(shape=(size,size,3))\n",
    "    base_net = EFNS[PARAMS.EFFNET](input_shape=(size,size,3),weights=path,include_top=False)\n",
    "    \n",
    "    x = base_net(inp)\n",
    "    x = tf.keras.layers.GlobalAvgPool2D()(x)\n",
    "    x = tf.keras.layers.Dropout(0.)(x)\n",
    "    x = tf.keras.layers.Dense(1,activation=\"sigmoid\")(x)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=inp, outputs=x)\n",
    "    loss = tf.keras.losses.BinaryCrossentropy()\n",
    "    model.compile(optimizer=\"adam\", loss=loss,metrics=[\"AUC\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "761c53fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(paths, is_label=False):\n",
    "    pred = []\n",
    "    ids = []\n",
    "    \n",
    "    ds = get_dataset(paths,labeled=False,return_image_ids=False,\n",
    "                    repeat=False,shuffle=False,dim=PARAMS.IMG_SIZES,batch_size=PARAMS.BATCH_SIZES*2)\n",
    "    for fold in PARAMS.FOLDS:\n",
    "        print(f\"{'#'*50} --> FOLD {fold + 1}\")\n",
    "        start_time = perf_counter()\n",
    "        \n",
    "        K.clear_session()\n",
    "        \n",
    "        with PARAMS.STRATEGY.scope():\n",
    "            model = build_model(PARAMS.IMG_SIZES, None)\n",
    "            print(\"\\t --> Loading Model\")\n",
    "            model.load_weights(f\"{PARAMS.PRETRAINED_MODEL_PATH}/fold-{fold}.h5\")\n",
    "            print(\"\\t <-- Model loaded\")\n",
    "        print(\"\\t-->Start Predict...\")\n",
    "        pred.append(model.predict(ds, verbose=1).flatten())\n",
    "        print(\"\\t<--Predict finished.\")\n",
    "        print(f\"<-- FOLD {fold + 1} finished, duration = {pref_counter() - start_time}s\")\n",
    "        \n",
    "        if is_label:\n",
    "            ds = get_dataset(paths,labeled=True,return_image_ids=False,\n",
    "                          repeat=False,shuffle=False,dim=PARAMS.IMG_SIZES,batch_size=PARAMS.BATCH_SIZES*2)\n",
    "            ids = np.array([target.numpy])\n",
    "            \n",
    "    return pred, ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bde90a0",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8fddfbfd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "################################################## --> FOLD 1\n",
      "\t --> Loading Model\n",
      "\t <-- Model loaded\n",
      "\t-->Start Predict...\n",
      "    173/Unknown - 100s 534ms/step"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_23204/568432187.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiles_train_g\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_23204/3417662527.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(paths, is_label)\u001b[0m\n\u001b[0;32m     17\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\t <-- Model loaded\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\t-->Start Predict...\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m         \u001b[0mpred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mpred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mids\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\g2net-tf\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1725\u001b[0m           \u001b[1;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1726\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1727\u001b[1;33m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1728\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1729\u001b[0m               \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\g2net-tf\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    887\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\g2net-tf\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    922\u001b[0m       \u001b[1;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    923\u001b[0m       \u001b[1;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 924\u001b[1;33m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    925\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    926\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[1;32m~\\anaconda3\\envs\\g2net-tf\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m   3023\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m-> 3024\u001b[1;33m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m   3025\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3026\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\g2net-tf\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1959\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1960\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1961\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1963\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\g2net-tf\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 596\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    597\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\g2net-tf\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "pred, target = predict(np.array(files_train_g), True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d1ce12",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv(f\"{PARAMS.COMPETITION_DATASET_PATH}/sample_submission.csv\")\n",
    "sub[\"id\"] = ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05dbf47",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv(\"submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
